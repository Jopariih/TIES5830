{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5IhhJDli81e"
      },
      "source": [
        "# Reformatting the Excel: Assumptions and stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5E_bEeYi81h"
      },
      "source": [
        "\n",
        "* Copied only vital information for the data generation.\n",
        "* Everything is in its own cell, so easy to import into a pandas dataframe.\n",
        "* Study number five (Jorge, 2015) had measurements for 6- and 12-week checkpoints for Pain, Function and QoL. Only 12 was added to the new excel, since assumedly that is the duration of the treatment/therapy.\n",
        "* O'Reilly paper was removed since they reported only the change in QoL, not the actual baseline value. Can't calculate the percentages based on just that.\n",
        "* Fransen paper has reported the WOMAC scores as inverse, so 0 represents the worst status and 100 the best. Might be that others have done that too\n",
        "    * _The WOMAC scores were reverse scored (100 = no pain\n",
        "or difficulty, 0 = extreme pain or difficulty), so that for all outcome measures higher scores are better scores._ https://www.jrheum.org/content/jrheum/28/1/156.full.pdf (That has been adjusted to the project_excel)\n",
        "\n",
        "\n",
        "* Group:\n",
        "    * Used 1 - exercise and 0 - control because it is also using in the objective functions\n",
        "\n",
        "* No of sessions:\n",
        "    * Also added because it is using in the objective functions\n",
        "    * 0 used for control assuming control fact do not have any sessions\n",
        "\n",
        "* Age:\n",
        "    * several different \"value types\" in paranthesis\n",
        "    * for some there is the +/- notation: not sure what that means (another notation for SD it turns out)\n",
        "    * for those cells with input like 71.9 (69.3, 74.6), in the paranthesis seems to be the 95% CI (only checked Cheung paper)\n",
        "    * for some there is mean (SD) notation used, SD being standard deviation\n",
        "    * According to the Wallis paper age structure may be Age_Mean_value (Age_SD)\n",
        "    * According to the Evcik paper the +/- notation follows SD\n",
        "\n",
        "* BMI:\n",
        "    * same issues as with age\n",
        "\n",
        "\n",
        "* Study participants/subjects:\n",
        "    * for simplicity's sake, it was assumed that all participants finished the therapies/participating in the study.\n",
        "        * (In reality this is not true, but cutting corners here a little bit, this is already getting out of hand)\n",
        "    * Do we need to keep Male and Female separate?  - _I don't think so. The information is not used in any of the objectives or in the data later, all the numbers are for the genders combined. Ideally, we should take the gender into account, but I think it is just complicating matters at this point. -J_\n",
        "\n",
        "* Pain levels:\n",
        "    * only the womac score included\n",
        "    * unless otherwise mentioned, it was assumed that the score was 0-20\n",
        "    * notice: not all were in the same scale, so needed to scale\n",
        "    * WOMAC (35 pain) don't know what this means and can't get access to the article to check so not doing anything to the values --> is foin\n",
        "    * 'changes' was interpreted to mean how much the original womac value changed, so the 'after' value would baseline+change.\n",
        "\n",
        "\n",
        "* Functionality\n",
        "    * can't get access to check what womac fc 85 means so leaving that as is (since googling didn't help either) --> again, is foin\n",
        "\n",
        "    \n",
        "* QoL\n",
        "    * different tests were used to test quality of life. If the scales were same, it was assumemd that they are comparable as is.\n",
        "    * everything was scaled to 0-100\n",
        "    * assuming that NHP emotional reaction is scaled from 0-100\n",
        "    * should maybe check if all scores are the \"same order\", like 0 is worst in all and 100 best. (Because for example for NHP: \"the total score for each domain is 100 where a score of 0 indicates good subjective health status and 100 indicates poor subjective health status.\" and I think SF-36 might use the scale the other way, 0 being worst and 100 being best)\n",
        "        * assuming 100 is the best score and 0 the worst\n",
        "        * I inversed the last study's QoL scores since they were the wrong way around (0 being the best and 100 worst)\n",
        "        * assuming others are OK, since the numbers make sense (they are rising after intervention/with time)\n",
        "    * Also for one paper there is no values, what should be done with that? (marked in grey)\n",
        "        * _This study has been dropped._\n",
        "\n",
        "\n",
        "    * **In the final report we shouold mention that several different metrics were used and that they might not be comparable**\n",
        "        * Although in theory, since we are comparing the change (or the percentage of improvement), they might not be that different?\n",
        "\n",
        "\n",
        "Color coding for the half finished table:\n",
        "* pink: need to somehow turn values into standard deviation\n",
        "    * *KNN imputation was used, right?*\n",
        "* green: need to find out what mm means and turn the value into scores (need to read the source paper)\n",
        "    * still don't know what mm means, but those were just another scale\n",
        "\n",
        "\n",
        "\n",
        "_TODO: add table columns and explain them_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K-mvGp6kd8Z"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0nbcCiFkmjR"
      },
      "source": [
        "Handling missing values using KNN imputation\n",
        "\n",
        "\n",
        "*I commented it for now, because I don't have the file in my gdrive, maybe you could update it so that it will work here too? -J*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kLM6ENgpkvOC"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from sklearn.impute import KNNImputer\n",
        "\n",
        "# #Access files from Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# df = pd.read_excel(\"/content/gdrive/MyDrive/TIES5830/project_excel.xlsx\", header=0)\n",
        "\n",
        "# print(\"Dataset:\")\n",
        "# print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "grwADaBVlDfA"
      },
      "outputs": [],
      "source": [
        "# # Display the number of missing values in each column\n",
        "# print(\"Missing Values in Each Column:\")\n",
        "# print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZauFE0WhlJfr"
      },
      "outputs": [],
      "source": [
        "# # Identify numeric columns\n",
        "# numeric_columns = df.select_dtypes(include=[float, int]).columns\n",
        "# print(\"Numeric Columns:\", numeric_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hPR8b1hKlMpg"
      },
      "outputs": [],
      "source": [
        "# # Create a DataFrame with only numeric columns for KNN imputation\n",
        "# numeric_df = df[numeric_columns]\n",
        "\n",
        "# # Initialize KNN Imputer\n",
        "# imputer = KNNImputer(n_neighbors=3)  # Choose a suitable number of neighbors\n",
        "\n",
        "# # Apply KNN imputation to the numeric columns\n",
        "# imputed_numeric_data = imputer.fit_transform(numeric_df)\n",
        "\n",
        "# # Convert back to a DataFrame with the original numeric column names\n",
        "# imputed_numeric_df = pd.DataFrame(imputed_numeric_data, columns=numeric_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7Bddq1VNlQEJ"
      },
      "outputs": [],
      "source": [
        "# # Reattach non-numeric columns to the imputed data\n",
        "# imputed_df = pd.concat([df[['reference']], imputed_numeric_df], axis=1)\n",
        "\n",
        "# print(\"Imputed Data:\")\n",
        "# print(imputed_df.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSPYh8PIi81k"
      },
      "source": [
        "# Data generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl1k9eSOi81l"
      },
      "source": [
        "* Find a method that can generate artificial data based on mean and variance\n",
        "* If a method cannot be found, need to assume distriubtion\n",
        "    * Compare that to some existing data (if there is such)\n",
        "        * if looks good, run with it\n",
        "        * but what if it does not look good? And if there is existing data, wouldn't it be easier to generate synthetic data based on that? There's ways to generate \"anonymous\" (synthetic) data from existing patient information, so that no patient confidiality is broken."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LppnJ01si81m"
      },
      "source": [
        "## Need to generate data for"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W67Ytduxi81n"
      },
      "source": [
        "\n",
        "* Age\n",
        "    * assumption: distribution probably skewed to the older side, since it is knee OA (older people more likely to have it)\n",
        "    * modeled as normal distribution, should maybe skew it a bit to the older side?\n",
        "* BMI\n",
        "    * Knee osteoarthiritis and bmi connected, could use that information?  https://www.sciencedirect.com/science/article/abs/pii/S1297319X11001370\n",
        "    * modeled as a normal distribution, should skew it somehow maybe?\n",
        "* Pain (baseline)\n",
        "    * modeled as normal distribution for now (same for all the rest - should probably think more)\n",
        "* Physical Functionality (baseline)\n",
        "* QoL (baseline)\n",
        "* Pain (after intervention)\n",
        "* Physical Functionality (after intervention)\n",
        "* QoL (after intervention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QkHrG3bSi81o"
      },
      "outputs": [],
      "source": [
        "# Importing the data\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the excel into a dataframe\n",
        "df = pd.read_excel('project_excel.xlsx', index_col='reference')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iAU0fqgi81q"
      },
      "source": [
        "## Data generation: normally distributed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ1vvIvCi81s"
      },
      "source": [
        "All generated data is stored in a dictionary, where the first column in excel (or the df index row) is the key and its value is another dataframe of the form\n",
        "\n",
        "\n",
        "{ <br>\n",
        "        'age': data_age, <br>\n",
        "        'bmi': data_bmi, <br>\n",
        "        'patients_num': num_of_participants,<br>\n",
        "        'pain_before': pain_before_data,<br>\n",
        "        'pain_after': pain_after_data,<br>\n",
        "        'functionality_before': func_before_data,<br>\n",
        "        'functionality_after': func_after_data,<br>\n",
        "        'QoL_before': qol_before_data,<br>\n",
        "        'QoL_after': qol_after_data<br>\n",
        "}\n",
        "\n",
        "### <span style=\"color:red\">NOTE:</span>\n",
        "<span style=\"color:red\"> This is a very naive approach and does not work well at all. </span> BUT it is enough to start working on the surrogates. We need to be cleverer if we want usable results. -J\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fiBmW0oi81t"
      },
      "source": [
        "**Reminder:**\n",
        " * pain on scale 0-20 (0 meaning no pain and being the best value)\n",
        "    * so pain_after should be assumed to be smaller than pain_before and calculating the percentage as (before-after)/before * 100\n",
        " * function 0-68 (0 being the best)\n",
        "    * percentage calculated as above\n",
        " * QoL on scale 0-100, the bigger the better.\n",
        "    * value is assumed to get higher after intervention/with time, so calculating the percentage as (after-before)/before * 100\n",
        "\n",
        "*Note: If the percentage values are negative, it means the improvement has been negative.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xQsXRcc0i81u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function that takes the whole column as input, divides it into pairs with the relevant mean and std\n",
        "# except the number of participants in the study is just an integer.\n",
        "# Then generates the data based on the above distributions and returns it in a dictionary\n",
        "def generate_data(info):\n",
        "    age = (info['age_mean'], info['age_std'])\n",
        "    bmi = (info['bmi_mean'], info['bmi_std'])\n",
        "    num_of_participants = int(info['num_of_subjects'])\n",
        "    pain_before = (info['pain_before_mean'], info['pain_before_std'])\n",
        "    pain_after = (info['pain_after_mean'], info['pain_after_std'])\n",
        "    func_before = (info['func_before_mean'], info['func_before_std'])\n",
        "    func_after = (info['func_after_mean'], info['func_after_std'])\n",
        "    qol_before = (info['QoL_before_mean'], info['QoL_before_std'])\n",
        "    qol_after = (info['QoL_after_mean'], info['QoL_after_std'])\n",
        "\n",
        "    # Generating the data\n",
        "    data_age = np.random.normal(age[0], age[1], num_of_participants)\n",
        "    data_bmi = np.random.normal(bmi[0], bmi[1], num_of_participants)\n",
        "    pain_before_data = np.random.normal(pain_before[0], pain_before[1], num_of_participants)\n",
        "    pain_after_data = np.random.normal(pain_after[0], pain_after[1], num_of_participants)\n",
        "    func_before_data = np.random.normal(func_before[0], func_before[1], num_of_participants)\n",
        "    func_after_data = np.random.normal(func_after[0], func_after[1], num_of_participants)\n",
        "    qol_before_data = np.random.normal(qol_before[0], qol_before[1], num_of_participants)\n",
        "    qol_after_data = np.random.normal(qol_after[0], qol_after[1], num_of_participants)\n",
        "\n",
        "    return {\n",
        "        'age': data_age,\n",
        "        'bmi': data_bmi,\n",
        "        'patients_num': num_of_participants,\n",
        "        'pain_before': pain_before_data,\n",
        "        'pain_after': pain_after_data,\n",
        "        'func_before': func_before_data,\n",
        "        'func_after': func_after_data,\n",
        "        'QoL_before': qol_before_data,\n",
        "        'QoL_after': qol_after_data\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3lE4gjVAi81v"
      },
      "outputs": [],
      "source": [
        "# A function for creating csv files for each exercise and control group\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def write_to_csv(data, filename, folder):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    filepath = os.path.join(folder, filename)\n",
        "\n",
        "    with open(filepath, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['age', 'bmi', 'pain_before', 'pain_after',\n",
        "                         'func_before', 'func_after', 'QoL_before', 'QoL_after'])\n",
        "\n",
        "        for i in range(data['patients_num']):\n",
        "            writer.writerow([data['age'][i], data['bmi'][i],\n",
        "                             data['pain_before'][i], data['pain_after'][i],\n",
        "                             data['func_before'][i], data['func_after'][i],\n",
        "                             data['QoL_before'][i], data['QoL_after'][i]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "v5YWUCyzi81w"
      },
      "outputs": [],
      "source": [
        "# # This piece of code generates the data. Now commented because it obviously overwrites the csv files each run\n",
        "# # and we do not wish to do that each time.\n",
        "\n",
        "# # Importing the excel into a dataframe\n",
        "# df = pd.read_excel('project_excel.xlsx', index_col='reference')\n",
        "\n",
        "# # This is the folder where the data is stuffed. The folder doesn't have to exist,\n",
        "# # if it does not exist, the folder will be created\n",
        "# folder = 'data_initial'\n",
        "\n",
        "# data_dict = {} # Storing all generated data here\n",
        "# for index, row in df.iterrows():\n",
        "#     # Generating data for each row in the df and adding that to the dict with the row index being the key\n",
        "#     data_dict[index] = generate_data(row)\n",
        "#     filename = f\"data_{index}.csv\"\n",
        "#     write_to_csv(data_dict[index], filename, folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YUyDRK9i81x"
      },
      "source": [
        "## <span style=\"color:red\">PROBLEMS WITH THE DATASETS</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Negative values in the objective function data, that should not be allowed to happen since the values aren't realistic.\n",
        "* Improvement rates are bloody ridiculous, they are not realistic at all. I think it is because of the negative values in the data, they are messing with the improvement calculations. Need to weed out the negative values and perhaps introduce some sort of correlation between the before and after levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH8EESGBi81x"
      },
      "source": [
        "### CSV shenanigans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function for importing the data from .csv files, returns it as a dictionary of dataframes\n",
        "# Takes the folder where .csv files are located as argument. \n",
        "# If the folder does not exist, sucks to be you.\n",
        "def import_data_from_csv(directory):\n",
        "    df_dicts = {}\n",
        "\n",
        "    # Looping the files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            filepath = os.path.join(directory, filename) # path to the file\n",
        "            df = pd.read_csv(filepath)\n",
        "\n",
        "            # Calculating the improvement percent for each patient (pain, function and QoL)\n",
        "            # Not sure if this is needed, but it is useful when looking at the \"realness\" of data\n",
        "            # and comparing the results to the expectation.\n",
        "\n",
        "            # Commented for now, in order to avoid pissin' in the StandardScaler's cereal. \n",
        "            # df['pain_improvement'] = (df['pain_before'] - df['pain_after'])/df['pain_before'] * 100\n",
        "            # df['func_improvement'] = (df['func_before'] - df['func_after'])/df['func_after'] * 100\n",
        "            # df['QoL_improvement'] = (df['QoL_after'] - df['QoL_before'])/df['QoL_before'] * 100\n",
        "            \n",
        "            # Key is the filename without the .csv ending\n",
        "            df_dicts[filename[:-4]] = df\n",
        "    return df_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CvwRDBWhi81y"
      },
      "outputs": [],
      "source": [
        "# Here importing the data from csv files into dataframes\n",
        "\n",
        "directory = \"./data_initial\"\n",
        "dataframes_dict = import_data_from_csv(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5DoDO_1Ii81y",
        "outputId": "b60cb0b9-4f47-4d1d-8698-670c27b3d434"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pain_before</th>\n",
              "      <th>pain_after</th>\n",
              "      <th>func_before</th>\n",
              "      <th>func_after</th>\n",
              "      <th>QoL_before</th>\n",
              "      <th>QoL_after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.994429</td>\n",
              "      <td>31.823120</td>\n",
              "      <td>3.945255</td>\n",
              "      <td>7.994302</td>\n",
              "      <td>15.065072</td>\n",
              "      <td>0.104071</td>\n",
              "      <td>86.578920</td>\n",
              "      <td>81.224085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57.950491</td>\n",
              "      <td>26.672613</td>\n",
              "      <td>3.954523</td>\n",
              "      <td>5.206808</td>\n",
              "      <td>19.645646</td>\n",
              "      <td>37.560577</td>\n",
              "      <td>42.440022</td>\n",
              "      <td>68.358751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.929268</td>\n",
              "      <td>26.114501</td>\n",
              "      <td>5.171387</td>\n",
              "      <td>12.147902</td>\n",
              "      <td>11.366587</td>\n",
              "      <td>43.776695</td>\n",
              "      <td>85.184797</td>\n",
              "      <td>56.680762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78.306072</td>\n",
              "      <td>24.260916</td>\n",
              "      <td>7.058493</td>\n",
              "      <td>6.334312</td>\n",
              "      <td>21.053131</td>\n",
              "      <td>23.891605</td>\n",
              "      <td>61.233277</td>\n",
              "      <td>62.361680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58.472637</td>\n",
              "      <td>23.716733</td>\n",
              "      <td>4.908522</td>\n",
              "      <td>7.337675</td>\n",
              "      <td>14.024951</td>\n",
              "      <td>5.947713</td>\n",
              "      <td>67.839827</td>\n",
              "      <td>63.052998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         age        bmi  pain_before  pain_after  func_before  func_after  \\\n",
              "0  55.994429  31.823120     3.945255    7.994302    15.065072    0.104071   \n",
              "1  57.950491  26.672613     3.954523    5.206808    19.645646   37.560577   \n",
              "2  65.929268  26.114501     5.171387   12.147902    11.366587   43.776695   \n",
              "3  78.306072  24.260916     7.058493    6.334312    21.053131   23.891605   \n",
              "4  58.472637  23.716733     4.908522    7.337675    14.024951    5.947713   \n",
              "\n",
              "   QoL_before  QoL_after  \n",
              "0   86.578920  81.224085  \n",
              "1   42.440022  68.358751  \n",
              "2   85.184797  56.680762  \n",
              "3   61.233277  62.361680  \n",
              "4   67.839827  63.052998  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframes_dict['data_an_2008_control'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4adla4QnjBlc"
      },
      "source": [
        "## Data generation: GAN\n",
        "\n",
        "*Again, commented this the GAN stuff, since we don't wanna be creating new files each time we run the notebook. Also, the gdrive thing don't work on my end.. :D -J*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n95raOXpjMP3"
      },
      "outputs": [],
      "source": [
        "# #!pip install numpy pandas tensorflow\n",
        "\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.layers import Input, Dense\n",
        "# from tensorflow.keras.models import Model\n",
        "# import os\n",
        "\n",
        "# #Access files from Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# df = pd.read_excel(\"/content/gdrive/MyDrive/project_excel.xlsx\", header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V2TcpHWwj7XI"
      },
      "outputs": [],
      "source": [
        "# # Define GAN components\n",
        "# def build_generator(latent_dim, output_dim):\n",
        "#     model_input = Input(shape=(latent_dim,))\n",
        "#     x = Dense(64, activation='relu')(model_input)\n",
        "#     x = Dense(128, activation='relu')(x)\n",
        "#     x = Dense(output_dim, activation='linear')(x)\n",
        "#     model = Model(model_input, x)\n",
        "#     return model\n",
        "\n",
        "# def build_discriminator(input_dim):\n",
        "#     model_input = Input(shape=(input_dim,))\n",
        "#     x = Dense(128, activation='relu')(model_input)\n",
        "#     x = Dense(64, activation='relu')(x)\n",
        "#     x = Dense(1, activation='sigmoid')(x)\n",
        "#     model = Model(model_input, x)\n",
        "#     return model\n",
        "\n",
        "# def build_gan(generator, discriminator):\n",
        "#     discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#     discriminator.trainable = False\n",
        "#     gan_input = Input(shape=(latent_dim,))\n",
        "#     generated_data = generator(gan_input)\n",
        "#     gan_output = discriminator(generated_data)\n",
        "#     gan = Model(gan_input, gan_output)\n",
        "#     gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "#     return gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gN96u_8ij-Xx"
      },
      "outputs": [],
      "source": [
        "# # Training function\n",
        "# def train_gan(generator, discriminator, gan, data, epochs=50, batch_size=16):\n",
        "#     for epoch in range(epochs):\n",
        "#         # Train discriminator\n",
        "#         noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "#         generated_data = generator.predict(noise)\n",
        "\n",
        "#         real_data = data[np.random.randint(0, data.shape[0], batch_size)]\n",
        "#         combined_data = np.vstack((real_data, generated_data))\n",
        "#         labels = np.array([1] * batch_size + [0] * batch_size)\n",
        "\n",
        "#         d_loss = discriminator.train_on_batch(combined_data, labels)\n",
        "\n",
        "#         # Train generator\n",
        "#         noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "#         misleading_labels = np.array([1] * batch_size)\n",
        "\n",
        "#         g_loss = gan.train_on_batch(noise, misleading_labels)\n",
        "\n",
        "#         if epoch % 100 == 0:\n",
        "#             print(f'Epoch {epoch} - Discriminator Loss: {d_loss}, Generator Loss: {g_loss}')\n",
        "\n",
        "# # Define parameters\n",
        "# latent_dim = 10\n",
        "# output_dim = 10\n",
        "\n",
        "# # Create directories for saving datasets\n",
        "# os.makedirs(\"synthetic_datasets\", exist_ok=True)\n",
        "\n",
        "# # Iterate over each reference to generate synthetic datasets\n",
        "# for _, row in df.iterrows():\n",
        "#     ref = row['reference']\n",
        "#     num_subjects = row['num_of_subjects']\n",
        "\n",
        "#     real_data = np.array([\n",
        "#         np.full(num_subjects, row['group']),\n",
        "#         np.full(num_subjects, row['no_of_sessions']),\n",
        "#         np.random.normal(row['age_mean'], row['age_std'], num_subjects),\n",
        "#         np.random.normal(row['bmi_mean'], row['bmi_std'], num_subjects),\n",
        "#         np.random.normal(row['pain_before_mean'], row['pain_before_std'], num_subjects),\n",
        "#         np.random.normal(row['pain_after_mean'], row['pain_after_std'], num_subjects),\n",
        "#         np.random.normal(row['func_before_mean'], row['func_before_std'], num_subjects),\n",
        "#         np.random.normal(row['func_after_mean'], row['func_after_std'], num_subjects),\n",
        "#         np.random.normal(row['QoL_before_mean'], row['QoL_before_std'], num_subjects),\n",
        "#         np.random.normal(row['QoL_after_mean'], row['QoL_after_std'], num_subjects)\n",
        "#     ]).T\n",
        "\n",
        "#     generator = build_generator(latent_dim, output_dim)\n",
        "#     discriminator = build_discriminator(output_dim)\n",
        "#     gan = build_gan(generator, discriminator)\n",
        "\n",
        "#     train_gan(generator, discriminator, gan, real_data, epochs=1000, batch_size=16)\n",
        "\n",
        "#     noise = np.random.normal(0, 1, (num_subjects, latent_dim))\n",
        "#     synthetic_data = generator.predict(noise)\n",
        "\n",
        "#     synthetic_df = pd.DataFrame(synthetic_data, columns=[\n",
        "#         'group', 'no_of_sessions', 'age', 'bmi', 'pain_before', 'pain_after', 'func_before', 'func_after', 'QoL_before', 'QoL_after'\n",
        "#     ])\n",
        "\n",
        "#     synthetic_df['group'] = synthetic_df['group'].round().astype(int)\n",
        "#     synthetic_df['no_of_sessions'] = synthetic_df['no_of_sessions'].round().astype(int)\n",
        "\n",
        "#     synthetic_df.to_csv(f\"synthetic_datasets/{ref}_synthetic.csv\", index=False)\n",
        "#     print(f\"Generated synthetic dataset for {ref}\")\n",
        "\n",
        "# print(\"All synthetic datasets have been generated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax9rv84Li811"
      },
      "source": [
        "# Data generation: normally distributed with correlations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## <span style=\"color:red\">NOTE</span>\n",
        "<span style=\"color:red\">This will be left half done, since it was done in parallel in case GAN did not render good results. It did tho, so no need to finish this!</span> \n",
        "\n",
        "The idea behind this was to have some \"proper\" data with correlations/covariances, since the initial version (random, normally distributed) was garbage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nOJ0LLfai813"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function that takes the whole column as input, divides it into pairs with the relevant mean and std\n",
        "# except the number of participants in the study is just an integer.\n",
        "# Then generates the correlated data using the correlation matrix generated anew for each generation round\n",
        "def generate_data_with_correlation(info):\n",
        "    age = (info['age_mean'], info['age_std'])\n",
        "    bmi = (info['bmi_mean'], info['bmi_std'])\n",
        "    num_of_participants = int(info['num_of_subjects'])\n",
        "    pain_before = (info['pain_before_mean'], info['pain_before_std'])\n",
        "    pain_after = (info['pain_after_mean'], info['pain_after_std'])\n",
        "    func_before = (info['func_before_mean'], info['func_before_std'])\n",
        "    func_after = (info['func_after_mean'], info['func_after_std'])\n",
        "    qol_before = (info['QoL_before_mean'], info['QoL_before_std'])\n",
        "    qol_after = (info['QoL_after_mean'], info['QoL_after_std'])\n",
        "\n",
        "\n",
        "    num_samples = num_of_participants\n",
        "\n",
        "    # The mean values of samples\n",
        "    mu = np.array([age[0], bmi[0], pain_before[0], func_before[0], qol_before[0], pain_after[0], func_after[0], qol_after[0]])\n",
        "\n",
        "    # The covariance matrix. Right now the values are randomly picked. Should be cleverer and also maybe make different\n",
        "    # correlation matrixes for each dataset/study?\n",
        "    r = np.array([\n",
        "    [1.0, 0.1, 0.1, 0.15, 0.15, -0.2, -0.3, -0.3],    # Variance of age\n",
        "    [0.1, 1.0, 0.1, 0.15, 0.15, -0.2, -0.3, -0.3],    # Variance of BMI\n",
        "    [0.1, 0.1, 1.0, 0.4, 0.4, -0.3, -0.4, -0.4],      # Covariance between age and pain_before, func_before, qol_before\n",
        "    [0.15, 0.15, 0.4, 1.0, 0.7, -0.5, -0.6, -0.7],    # Covariance between BMI and pain_before, func_before, qol_before\n",
        "    [0.15, 0.15, 0.4, 0.7, 1.0, -0.5, -0.6, -0.7],    # Variance of pain_before, func_before, qol_before\n",
        "    [-0.2, -0.2, -0.3, -0.5, -0.5, 1.0, 0.8, 0.7],    # Covariance between age and pain_after, func_after, qol_after\n",
        "    [-0.3, -0.3, -0.4, -0.6, -0.6, 0.8, 1.0, 0.9],    # Covariance between BMI and pain_after, func_after, qol_after\n",
        "    [-0.3, -0.3, -0.4, -0.7, -0.7, 0.7, 0.9, 1.0]     # Variance of pain_after, func_after, qol_after\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    # Generate the random samples.\n",
        "    rng = np.random.default_rng()\n",
        "    y = rng.multivariate_normal(mu, r, size=num_samples)\n",
        "\n",
        "    print(y)\n",
        "\n",
        "    # Generating the data\n",
        "    data_age = np.random.normal(age[0], age[1], num_of_participants)\n",
        "    data_bmi = np.random.normal(bmi[0], bmi[1], num_of_participants)\n",
        "    pain_before_data = np.random.normal(pain_before[0], pain_before[1], num_of_participants)\n",
        "    pain_after_data = np.random.normal(pain_after[0], pain_after[1], num_of_participants)\n",
        "    func_before_data = np.random.normal(func_before[0], func_before[1], num_of_participants)\n",
        "    func_after_data = np.random.normal(func_after[0], func_after[1], num_of_participants)\n",
        "    qol_before_data = np.random.normal(qol_before[0], qol_before[1], num_of_participants)\n",
        "    qol_after_data = np.random.normal(qol_after[0], qol_after[1], num_of_participants)\n",
        "\n",
        "    # Calculating the improvement percent for each patient (pain, function and QoL)\n",
        "    pain_improvement = (pain_before_data - pain_after_data)/pain_before_data * 100\n",
        "    func_improvement = (func_before_data - func_after_data)/func_before_data * 100\n",
        "    qol_improvement = (qol_after_data - qol_before_data)/qol_before_data * 100\n",
        "\n",
        "    return {\n",
        "        'age': data_age,\n",
        "        'bmi': data_bmi,\n",
        "        'patients_num': num_of_participants,\n",
        "        'pain_before': pain_before_data,\n",
        "        'pain_after': pain_after_data,\n",
        "        'pain_improvement': pain_improvement,\n",
        "        'func_before': func_before_data,\n",
        "        'func_after': func_after_data,\n",
        "        'func_improvement': func_improvement,\n",
        "        'QoL_before': qol_before_data,\n",
        "        'QoL_after': qol_after_data,\n",
        "        'QoL_improvement': qol_improvement\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5yQTwTjUi814"
      },
      "outputs": [],
      "source": [
        "# Importing the excel into a dataframe\n",
        "df = pd.read_excel('project_excel.xlsx', index_col='reference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5YdTRmtbi815"
      },
      "outputs": [],
      "source": [
        "# This piece of code generates the data.\n",
        "\n",
        "# This is the folder where the data is stuffed. The folder doesn't have to exist,\n",
        "# if it does not exist, the folder will be created\n",
        "folder = 'data_correlated'\n",
        "\n",
        "correlated_synthetic_data_dict = {} # Storing all generated data here\n",
        "# for index, row in df.iterrows():\n",
        "#     # Generating data for each row in the df and adding that to the dict with the row index being the key\n",
        "#     correlated_synthetic_data_dict[index] = generate_data(row)\n",
        "#     filename = f\"data_{index}.csv\"\n",
        "#     write_to_csv(correlated_synthetic_data_dict[index], filename, folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iUelviuNi815",
        "outputId": "54104b78-77d9-48ee-a7a4-ab830e081231"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pain_before</th>\n",
              "      <th>pain_after</th>\n",
              "      <th>func_before</th>\n",
              "      <th>func_after</th>\n",
              "      <th>QoL_before</th>\n",
              "      <th>QoL_after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.994429</td>\n",
              "      <td>31.823120</td>\n",
              "      <td>3.945255</td>\n",
              "      <td>7.994302</td>\n",
              "      <td>15.065072</td>\n",
              "      <td>0.104071</td>\n",
              "      <td>86.578920</td>\n",
              "      <td>81.224085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57.950491</td>\n",
              "      <td>26.672613</td>\n",
              "      <td>3.954523</td>\n",
              "      <td>5.206808</td>\n",
              "      <td>19.645646</td>\n",
              "      <td>37.560577</td>\n",
              "      <td>42.440022</td>\n",
              "      <td>68.358751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.929268</td>\n",
              "      <td>26.114501</td>\n",
              "      <td>5.171387</td>\n",
              "      <td>12.147902</td>\n",
              "      <td>11.366587</td>\n",
              "      <td>43.776695</td>\n",
              "      <td>85.184797</td>\n",
              "      <td>56.680762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>78.306072</td>\n",
              "      <td>24.260916</td>\n",
              "      <td>7.058493</td>\n",
              "      <td>6.334312</td>\n",
              "      <td>21.053131</td>\n",
              "      <td>23.891605</td>\n",
              "      <td>61.233277</td>\n",
              "      <td>62.361680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58.472637</td>\n",
              "      <td>23.716733</td>\n",
              "      <td>4.908522</td>\n",
              "      <td>7.337675</td>\n",
              "      <td>14.024951</td>\n",
              "      <td>5.947713</td>\n",
              "      <td>67.839827</td>\n",
              "      <td>63.052998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         age        bmi  pain_before  pain_after  func_before  func_after  \\\n",
              "0  55.994429  31.823120     3.945255    7.994302    15.065072    0.104071   \n",
              "1  57.950491  26.672613     3.954523    5.206808    19.645646   37.560577   \n",
              "2  65.929268  26.114501     5.171387   12.147902    11.366587   43.776695   \n",
              "3  78.306072  24.260916     7.058493    6.334312    21.053131   23.891605   \n",
              "4  58.472637  23.716733     4.908522    7.337675    14.024951    5.947713   \n",
              "\n",
              "   QoL_before  QoL_after  \n",
              "0   86.578920  81.224085  \n",
              "1   42.440022  68.358751  \n",
              "2   85.184797  56.680762  \n",
              "3   61.233277  62.361680  \n",
              "4   67.839827  63.052998  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframes_dict['data_an_2008_control'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A9Yv-Phi816"
      },
      "source": [
        "# GAN-generated data from CSV to dictionary\n",
        "Generation was originally done in another code file. Code added above "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cOPWTgLyi817"
      },
      "outputs": [],
      "source": [
        "# Here importing the data from csv files into dataframes\n",
        "\n",
        "# the folder where the data is hanging out\n",
        "# this will import ALL the .csv files within that folder\n",
        "directory = \"./GAN_Generated\"\n",
        "dataframes_dict_gan = import_data_from_csv(directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uOlQAogei817",
        "outputId": "3499e3d6-6038-4f15-9f09-33b6cb8a8a1d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>no_of_sessions</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pain_before</th>\n",
              "      <th>pain_after</th>\n",
              "      <th>func_before</th>\n",
              "      <th>func_after</th>\n",
              "      <th>QoL_before</th>\n",
              "      <th>QoL_after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>77.117580</td>\n",
              "      <td>14.539472</td>\n",
              "      <td>5.588644</td>\n",
              "      <td>5.520327</td>\n",
              "      <td>21.988897</td>\n",
              "      <td>22.629564</td>\n",
              "      <td>70.022480</td>\n",
              "      <td>73.527466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>74.211500</td>\n",
              "      <td>13.635116</td>\n",
              "      <td>5.348004</td>\n",
              "      <td>5.092411</td>\n",
              "      <td>21.597746</td>\n",
              "      <td>21.567600</td>\n",
              "      <td>67.242170</td>\n",
              "      <td>71.313020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>63.971367</td>\n",
              "      <td>11.288850</td>\n",
              "      <td>4.698689</td>\n",
              "      <td>4.055223</td>\n",
              "      <td>18.586061</td>\n",
              "      <td>18.242400</td>\n",
              "      <td>57.515636</td>\n",
              "      <td>61.197197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>62.499893</td>\n",
              "      <td>12.081700</td>\n",
              "      <td>4.425854</td>\n",
              "      <td>4.508512</td>\n",
              "      <td>17.868702</td>\n",
              "      <td>18.509598</td>\n",
              "      <td>56.733430</td>\n",
              "      <td>59.383293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>51</td>\n",
              "      <td>88.805970</td>\n",
              "      <td>16.424040</td>\n",
              "      <td>6.568262</td>\n",
              "      <td>5.840533</td>\n",
              "      <td>25.406647</td>\n",
              "      <td>25.530130</td>\n",
              "      <td>80.040184</td>\n",
              "      <td>84.478540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   group  no_of_sessions        age        bmi  pain_before  pain_after  \\\n",
              "0      5              44  77.117580  14.539472     5.588644    5.520327   \n",
              "1      6              43  74.211500  13.635116     5.348004    5.092411   \n",
              "2      4              37  63.971367  11.288850     4.698689    4.055223   \n",
              "3      4              36  62.499893  12.081700     4.425854    4.508512   \n",
              "4      6              51  88.805970  16.424040     6.568262    5.840533   \n",
              "\n",
              "   func_before  func_after  QoL_before  QoL_after  \n",
              "0    21.988897   22.629564   70.022480  73.527466  \n",
              "1    21.597746   21.567600   67.242170  71.313020  \n",
              "2    18.586061   18.242400   57.515636  61.197197  \n",
              "3    17.868702   18.509598   56.733430  59.383293  \n",
              "4    25.406647   25.530130   80.040184  84.478540  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframes_dict_gan['an_2008_exercise_synthetic'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQtZ9pSUi818"
      },
      "source": [
        "# Surrogates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alYjcZkoi818"
      },
      "source": [
        "Surrogates are only fit for the exercise groups, control groups are ignored fully here. \n",
        "\n",
        "The goal is to see if after intervention values can be predicted using age, BMI and the baseline values. (For each objective, so trying to predict pain_after with age, BMI and pain_before.) In the first version, age, BMI and baseline value were used to predict the improvement (in percentages) of the objective. \n",
        "\n",
        "Also not sure if the performance metric R^2 was a good choice, it was just convenient \n",
        "    --> TODO: k-cross fold validation!? Said to be just a few lines of code. Should figure that out.\n",
        "\n",
        "- Chosen surrogates for further evaluation and testing:\n",
        "    - SVM\n",
        "    - Random Forest\n",
        "    - Gradient Boost Regression\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFuaYvdXi819"
      },
      "source": [
        "## Scaling data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* Fitting the surrogates only for the exercise groups.\n",
        "* Scaling the data since some of the methods (like SVM) work better with scaled data (sensitivity to outliers etc)\n",
        "    * StandardScaler was used, although it was said to be \"sensitive to outliers, and the features may scale differently from each other in the presence of outliers\"\n",
        "    * Unsure what counts as outlier, IMO the generated data don't contain outliars that large that they would be a worry.\n",
        "    * Although! The improvement rates might be a different story!! --> deleting the code that calculates the improvement in percentages, since (with the crap data) it in some cases lead to results such as 1000 and more. Should be fine.\n",
        "* We are assuming that all the data is somewhat similar so just one scaler for all is enough\n",
        "    *  Also need to remember to unscale the data in the end and only one scaler makes it easier!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function for scaling the data. Using same scaler for everything since the values are roughly the same with each dataset. \n",
        "# NOTE: The scaler however does change between data_initial and gan_generated!\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function for scaling the data\n",
        "def scale_data(data_dict, feature_columns, target_columns):\n",
        "    feature_scaler = StandardScaler()\n",
        "    target_scaler_pain = StandardScaler()\n",
        "    target_scaler_func = StandardScaler()\n",
        "    target_scaler_qol = StandardScaler()\n",
        "\n",
        "    # Scale features and targets\n",
        "    scaled_features = feature_scaler.fit_transform(pd.concat([data_dict[key][feature_columns] for key in data_dict.keys()], axis=0))\n",
        "    scaled_pain = target_scaler_pain.fit_transform(pd.concat([data_dict[key][target_columns[0]] for key in data_dict.keys()], axis=0).values.reshape(-1, 1))\n",
        "    scaled_func = target_scaler_func.fit_transform(pd.concat([data_dict[key][target_columns[1]] for key in data_dict.keys()], axis=0).values.reshape(-1, 1))\n",
        "    scaled_qol = target_scaler_qol.fit_transform(pd.concat([data_dict[key][target_columns[2]] for key in data_dict.keys()], axis=0).values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "    # Update each DataFrame with scaled features and targets\n",
        "    for key in data_dict.keys():\n",
        "        data_dict[key][feature_columns] = scaled_features[:len(data_dict[key])]\n",
        "        data_dict[key][target_columns[0]] = scaled_pain[:len(data_dict[key])]\n",
        "        data_dict[key][target_columns[1]] = scaled_func[:len(data_dict[key])]\n",
        "        data_dict[key][target_columns[2]] = scaled_qol[:len(data_dict[key])]\n",
        "\n",
        "    return feature_scaler, target_scaler_pain, target_scaler_func, target_scaler_qol\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['age', 'bmi', 'pain_before', 'func_before', 'QoL_before']\n",
        "targets = ['pain_after', 'func_after', 'QoL_after']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gmG93DCsi81-",
        "outputId": "95c2ff96-0b15-4536-92b9-fbcf86c7f806"
      },
      "outputs": [],
      "source": [
        "# Extracting only the dataframes about the exercise groups\n",
        "ex_keys = [k for k in dataframes_dict.keys() if \"exercise\" in k]\n",
        "exercise_dataframes_dict = {}\n",
        "for key in ex_keys:\n",
        "    exercise_dataframes_dict[key] = dataframes_dict[key].copy()\n",
        "\n",
        "\n",
        "# Scaling the data. This will not make a copy, \n",
        "# it is scaling the original! Scaler is returned for further use.\n",
        "f_scaler, pain_scaler, func_scaler, qol_scaler = scale_data(exercise_dataframes_dict, features, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IHjA2t86i82A",
        "outputId": "6233f09b-3651-454f-a9b3-1f9c4c7477cd"
      },
      "outputs": [],
      "source": [
        "# Extracting only the dataframes about the exercise groups\n",
        "ex_keys_gan = [k for k in dataframes_dict_gan.keys() if \"exercise\" in k]\n",
        "exercise_dataframes_dict_gan = {}\n",
        "for key in ex_keys_gan:\n",
        "    exercise_dataframes_dict_gan[key] = dataframes_dict_gan[key].copy()\n",
        "\n",
        "# Scaling GAN data, using the functions above\n",
        "f_scaler_gan, pain_scaler_gan, func_scaler_gan, qol_scaler_gan = scale_data(exercise_dataframes_dict_gan, features, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>group</th>\n",
              "      <th>no_of_sessions</th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pain_before</th>\n",
              "      <th>pain_after</th>\n",
              "      <th>func_before</th>\n",
              "      <th>func_after</th>\n",
              "      <th>QoL_before</th>\n",
              "      <th>QoL_after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>0.813384</td>\n",
              "      <td>-1.166628</td>\n",
              "      <td>-0.722367</td>\n",
              "      <td>0.255300</td>\n",
              "      <td>-0.193940</td>\n",
              "      <td>0.156493</td>\n",
              "      <td>0.850382</td>\n",
              "      <td>0.381340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>43</td>\n",
              "      <td>0.658576</td>\n",
              "      <td>-1.246420</td>\n",
              "      <td>-0.757251</td>\n",
              "      <td>0.180167</td>\n",
              "      <td>-0.227492</td>\n",
              "      <td>0.060464</td>\n",
              "      <td>0.728915</td>\n",
              "      <td>0.305067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>37</td>\n",
              "      <td>0.113080</td>\n",
              "      <td>-1.453435</td>\n",
              "      <td>-0.851378</td>\n",
              "      <td>-0.001941</td>\n",
              "      <td>-0.485824</td>\n",
              "      <td>-0.240220</td>\n",
              "      <td>0.303982</td>\n",
              "      <td>-0.043359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>36</td>\n",
              "      <td>0.034694</td>\n",
              "      <td>-1.383480</td>\n",
              "      <td>-0.890929</td>\n",
              "      <td>0.077647</td>\n",
              "      <td>-0.547356</td>\n",
              "      <td>-0.216058</td>\n",
              "      <td>0.269809</td>\n",
              "      <td>-0.105836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>51</td>\n",
              "      <td>1.436030</td>\n",
              "      <td>-1.000350</td>\n",
              "      <td>-0.580358</td>\n",
              "      <td>0.311521</td>\n",
              "      <td>0.099222</td>\n",
              "      <td>0.418779</td>\n",
              "      <td>1.288035</td>\n",
              "      <td>0.758535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>66</td>\n",
              "      <td>2.780974</td>\n",
              "      <td>-0.665643</td>\n",
              "      <td>-0.295337</td>\n",
              "      <td>0.568172</td>\n",
              "      <td>0.779962</td>\n",
              "      <td>1.087691</td>\n",
              "      <td>2.295097</td>\n",
              "      <td>1.640300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>53</td>\n",
              "      <td>1.621174</td>\n",
              "      <td>-0.821288</td>\n",
              "      <td>-0.579563</td>\n",
              "      <td>0.488272</td>\n",
              "      <td>0.170831</td>\n",
              "      <td>0.604624</td>\n",
              "      <td>1.464174</td>\n",
              "      <td>0.869244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>64</td>\n",
              "      <td>2.679129</td>\n",
              "      <td>-0.650577</td>\n",
              "      <td>-0.333156</td>\n",
              "      <td>0.568779</td>\n",
              "      <td>0.696522</td>\n",
              "      <td>1.000109</td>\n",
              "      <td>2.200258</td>\n",
              "      <td>1.538607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>41</td>\n",
              "      <td>0.495571</td>\n",
              "      <td>-1.254436</td>\n",
              "      <td>-0.809606</td>\n",
              "      <td>0.163395</td>\n",
              "      <td>-0.361105</td>\n",
              "      <td>-0.021116</td>\n",
              "      <td>0.600125</td>\n",
              "      <td>0.159100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>52</td>\n",
              "      <td>1.552913</td>\n",
              "      <td>-0.976088</td>\n",
              "      <td>-0.465756</td>\n",
              "      <td>0.344831</td>\n",
              "      <td>0.156579</td>\n",
              "      <td>0.467742</td>\n",
              "      <td>1.381841</td>\n",
              "      <td>0.863612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7</td>\n",
              "      <td>60</td>\n",
              "      <td>2.217002</td>\n",
              "      <td>-0.827488</td>\n",
              "      <td>-0.394187</td>\n",
              "      <td>0.485534</td>\n",
              "      <td>0.465637</td>\n",
              "      <td>0.824258</td>\n",
              "      <td>1.870173</td>\n",
              "      <td>1.267178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8</td>\n",
              "      <td>63</td>\n",
              "      <td>2.521886</td>\n",
              "      <td>-0.601416</td>\n",
              "      <td>-0.435643</td>\n",
              "      <td>0.610151</td>\n",
              "      <td>0.619283</td>\n",
              "      <td>1.026750</td>\n",
              "      <td>2.137668</td>\n",
              "      <td>1.452470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6</td>\n",
              "      <td>46</td>\n",
              "      <td>0.916683</td>\n",
              "      <td>-1.164214</td>\n",
              "      <td>-0.742798</td>\n",
              "      <td>0.191237</td>\n",
              "      <td>-0.143252</td>\n",
              "      <td>0.174767</td>\n",
              "      <td>0.889327</td>\n",
              "      <td>0.435297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6</td>\n",
              "      <td>54</td>\n",
              "      <td>1.690567</td>\n",
              "      <td>-0.779442</td>\n",
              "      <td>-0.619338</td>\n",
              "      <td>0.529826</td>\n",
              "      <td>0.176817</td>\n",
              "      <td>0.610358</td>\n",
              "      <td>1.524982</td>\n",
              "      <td>0.901001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              "0       5              44  0.813384 -1.166628    -0.722367    0.255300   \n",
              "1       6              43  0.658576 -1.246420    -0.757251    0.180167   \n",
              "2       4              37  0.113080 -1.453435    -0.851378   -0.001941   \n",
              "3       4              36  0.034694 -1.383480    -0.890929    0.077647   \n",
              "4       6              51  1.436030 -1.000350    -0.580358    0.311521   \n",
              "5       8              66  2.780974 -0.665643    -0.295337    0.568172   \n",
              "6       6              53  1.621174 -0.821288    -0.579563    0.488272   \n",
              "7       8              64  2.679129 -0.650577    -0.333156    0.568779   \n",
              "8       5              41  0.495571 -1.254436    -0.809606    0.163395   \n",
              "9       6              52  1.552913 -0.976088    -0.465756    0.344831   \n",
              "10      7              60  2.217002 -0.827488    -0.394187    0.485534   \n",
              "11      8              63  2.521886 -0.601416    -0.435643    0.610151   \n",
              "12      6              46  0.916683 -1.164214    -0.742798    0.191237   \n",
              "13      6              54  1.690567 -0.779442    -0.619338    0.529826   \n",
              "\n",
              "    func_before  func_after  QoL_before  QoL_after  \n",
              "0     -0.193940    0.156493    0.850382   0.381340  \n",
              "1     -0.227492    0.060464    0.728915   0.305067  \n",
              "2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              "3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              "4      0.099222    0.418779    1.288035   0.758535  \n",
              "5      0.779962    1.087691    2.295097   1.640300  \n",
              "6      0.170831    0.604624    1.464174   0.869244  \n",
              "7      0.696522    1.000109    2.200258   1.538607  \n",
              "8     -0.361105   -0.021116    0.600125   0.159100  \n",
              "9      0.156579    0.467742    1.381841   0.863612  \n",
              "10     0.465637    0.824258    1.870173   1.267178  \n",
              "11     0.619283    1.026750    2.137668   1.452470  \n",
              "12    -0.143252    0.174767    0.889327   0.435297  \n",
              "13     0.176817    0.610358    1.524982   0.901001  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exercise_dataframes_dict_gan['an_2008_exercise_synthetic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.39299292]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value = np.array([12])\n",
        "value = value.reshape(1,-1)\n",
        "pain_scaler_gan.transform(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'an_2008_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0       5              44  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1       6              43  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2       4              37  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3       4              36  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4       6              51  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5       8              66  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6       6              53  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7       8              64  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8       5              41  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9       6              52  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10      7              60  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11      8              63  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12      6              46  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13      6              54  1.690567 -0.779442    -0.619338    0.529826   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  ,\n",
              " 'cheung_2014_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0       4              34  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1       5              46  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2       3              33  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3       4              38  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4       4              35  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5       4              38  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6       3              34  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7       5              45  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8       3              34  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9       5              44  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10      4              34  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11      4              31  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12      4              37  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13      5              42  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14      4              35  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15      4              39  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16      4              37  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17      4              39  0.814848  1.535685     0.908779   -0.345939   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  ,\n",
              " 'evcik_2002_exercise1_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0       4              23  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1       3              17  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2       3              18  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3       3              18  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4       2              14  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5       3              18  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6       3              18  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7       4              21  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8       4              23  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9       4              27  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10      3              19  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11      3              19  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12      5              24  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13      4              23  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14      6              30  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15      3              18  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16      3              19  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17      3              15  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18      3              20  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19      4              24  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20      2              14  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21      3              19  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22      4              21  0.244656  0.907786     0.513677   -0.381854   \n",
              " 23      2              16  1.299719  1.907847     1.132861   -0.306720   \n",
              " 24      4              23  0.300545  0.971811     0.551178   -0.417529   \n",
              " 25      3              19  0.016673  0.701026     0.405836   -0.355972   \n",
              " 26      6              31  0.605856  1.292268     0.767414   -0.334519   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  \n",
              " 23     2.121856    1.164272    0.669878   0.681651  \n",
              " 24     1.192464    0.540647    0.075988   0.101124  \n",
              " 25     0.928652    0.334020   -0.137238  -0.114068  \n",
              " 26     1.479428    0.766106    0.255104   0.282461  ,\n",
              " 'evcik_2002_exercise2_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0       5             103  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1       4              81  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2       4              88  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3       5             110  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4       4              79  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5       5             109  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6       4              94  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7       7             152  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8       4              91  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9       5              97  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10      4              80  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11      5             101  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12      4              92  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13      6             118  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14      4              89  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15      4              99  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16      5             106  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17      4              98  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18      6             113  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19      4              80  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20      4              89  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21      4              92  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22      4              83  0.244656  0.907786     0.513677   -0.381854   \n",
              " 23      5              99  1.299719  1.907847     1.132861   -0.306720   \n",
              " 24      5             108  0.300545  0.971811     0.551178   -0.417529   \n",
              " 25      5             111  0.016673  0.701026     0.405836   -0.355972   \n",
              " 26      5              95  0.605856  1.292268     0.767414   -0.334519   \n",
              " 27      3              69  1.167983  1.820518     1.054672   -0.303858   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  \n",
              " 23     2.121856    1.164272    0.669878   0.681651  \n",
              " 24     1.192464    0.540647    0.075988   0.101124  \n",
              " 25     0.928652    0.334020   -0.137238  -0.114068  \n",
              " 26     1.479428    0.766106    0.255104   0.282461  \n",
              " 27     2.008007    1.122259    0.591390   0.595060  ,\n",
              " 'fransen_2001_exercise1_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -1              10  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -1               8  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -2               9  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -1              18  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -1               6  1.436030 -1.000350    -0.580358    0.311521   \n",
              " ..    ...             ...       ...       ...          ...         ...   \n",
              " 57     -1               6 -0.460317 -0.398963    -0.228410    1.290393   \n",
              " 58     -2               8  1.287791  0.876025     0.520655    2.502562   \n",
              " 59     -1               9  0.901348  0.791492     2.338470    1.747137   \n",
              " 60     -1               9  0.007206  0.116890     1.481533    1.201386   \n",
              " 61     -2               6  0.331741  0.329869     1.724279    1.347427   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " ..          ...         ...         ...        ...  \n",
              " 57    -0.004847   -0.653838    0.942754   0.604142  \n",
              " 58     1.226998    0.134377    2.910758   2.281282  \n",
              " 59    -0.508474    0.057853    1.577313   2.393072  \n",
              " 60    -0.827102   -0.354967    0.781002   1.423377  \n",
              " 61    -0.649484   -0.201169    1.048028   1.747700  \n",
              " \n",
              " [62 rows x 10 columns],\n",
              " 'fransen_2001_exercise2_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0       4              23  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1       3              20  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2       4              23  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3       4              25  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4       7              39  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5       4              25  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6       4              23  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7       3              18  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8       4              25  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9       5              31  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10      3              20  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11      5              29  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12      5              28  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13      3              18  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14      7              39  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15      3              20  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16      5              28  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17      4              27  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18      3              20  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19      4              28  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20      5              34  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21      4              25  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22      4              22  0.244656  0.907786     0.513677   -0.381854   \n",
              " 23      6              36  1.299719  1.907847     1.132861   -0.306720   \n",
              " 24      6              33  0.300545  0.971811     0.551178   -0.417529   \n",
              " 25      4              24  0.016673  0.701026     0.405836   -0.355972   \n",
              " 26      4              24  0.605856  1.292268     0.767414   -0.334519   \n",
              " 27      3              21  1.167983  1.820518     1.054672   -0.303858   \n",
              " 28      3              20  0.481297  1.148127     0.704194   -0.276711   \n",
              " 29      3              21  0.789552  1.448209     0.829720   -0.436769   \n",
              " 30      6              39  0.619339  1.277818     0.696554   -0.399094   \n",
              " 31      3              20  0.839406  1.509129     0.886167   -0.377982   \n",
              " 32      4              21  0.115807 -0.007128     0.030754    1.613475   \n",
              " 33      5              31 -0.761050 -0.617745    -0.394056    1.064303   \n",
              " 34      5              32 -0.668972 -0.547900    -0.321317    1.104277   \n",
              " 35      5              29 -0.678508 -0.567308    -0.358142    1.118812   \n",
              " 36      7              40 -1.227399 -0.967209    -0.595189    0.717307   \n",
              " 37      5              29 -0.550643 -0.495376    -0.253163    1.168797   \n",
              " 38      4              24 -0.621120 -0.509303    -0.306287    1.189267   \n",
              " 39      4              25 -0.155472 -0.162730    -0.114874    1.480226   \n",
              " 40      7              41  0.138872  0.048900     0.022802    1.658978   \n",
              " 41      7              39  0.753393  0.426842     0.317130    1.986081   \n",
              " 42      8              42 -0.443952 -0.384816    -0.227251    1.267888   \n",
              " 43      4              28 -0.584436 -0.522663    -0.288824    1.143206   \n",
              " 44      5              31  0.193666  0.102280     0.034443    1.742081   \n",
              " 45      5              28  0.022354 -0.048766    -0.021246    1.595927   \n",
              " 46      4              28  1.143730  0.799905     0.469185    2.453373   \n",
              " 47      3              20 -0.612178 -0.529006    -0.307592    1.141337   \n",
              " 48      7              40 -0.533603 -0.411919    -0.281926    1.206811   \n",
              " 49      4              27 -1.126906 -0.885846    -0.576036    0.818715   \n",
              " 50      7              39 -0.303374 -0.303683    -0.155327    1.303709   \n",
              " 51      5              32  0.268803  0.092341     0.114931    1.716284   \n",
              " 52      5              31 -1.189078 -0.935349    -0.580387    0.723837   \n",
              " 53      5              30 -0.415965 -0.378426    -0.215693    1.281510   \n",
              " 54      4              28 -0.175666 -0.201930    -0.078359    1.450372   \n",
              " 55      5              28 -0.873902 -0.722042    -0.433265    0.919167   \n",
              " 56      3              17  0.092432 -0.021016    -0.001065    1.613601   \n",
              " 57      5              27 -0.460317 -0.398963    -0.228410    1.290393   \n",
              " 58      5              31  1.287791  0.876025     0.520655    2.502562   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  \n",
              " 23     2.121856    1.164272    0.669878   0.681651  \n",
              " 24     1.192464    0.540647    0.075988   0.101124  \n",
              " 25     0.928652    0.334020   -0.137238  -0.114068  \n",
              " 26     1.479428    0.766106    0.255104   0.282461  \n",
              " 27     2.008007    1.122259    0.591390   0.595060  \n",
              " 28     1.345654    0.655302    0.162720   0.186917  \n",
              " 29     1.694937    0.894315    0.375886   0.392707  \n",
              " 30     1.517762    0.735358    0.254777   0.273411  \n",
              " 31     1.709829    0.924558    0.418218   0.443179  \n",
              " 32     0.368374   -0.374807    1.563941   1.129932  \n",
              " 33    -0.233425   -0.754747    0.607698   0.305514  \n",
              " 34    -0.158193   -0.720412    0.709834   0.394054  \n",
              " 35    -0.187082   -0.735035    0.708282   0.381804  \n",
              " 36    -0.576785   -0.985574    0.087837  -0.147852  \n",
              " 37    -0.100959   -0.703932    0.819299   0.491028  \n",
              " 38    -0.144846   -0.703582    0.774767   0.441960  \n",
              " 39     0.235921   -0.494435    1.309058   0.901626  \n",
              " 40     0.415322   -0.385155    1.626928   1.178600  \n",
              " 41     0.806420   -0.099017    2.265536   1.751979  \n",
              " 42     0.008189   -0.621611    0.981940   0.635543  \n",
              " 43    -0.142067   -0.708145    0.801570   0.454041  \n",
              " 44     0.484796   -0.357912    1.735640   1.237289  \n",
              " 45     0.345261   -0.409398    1.496518   1.072955  \n",
              " 46     1.174366    0.073918    2.775217   2.163446  \n",
              " 47    -0.145453   -0.704321    0.760075   0.441146  \n",
              " 48    -0.048408   -0.653614    0.909941   0.558005  \n",
              " 49    -0.502139   -0.928866    0.216014  -0.048441  \n",
              " 50     0.072122   -0.573201    1.106046   0.731829  \n",
              " 51     0.491162   -0.325860    1.749724   1.272784  \n",
              " 52    -0.554270   -0.940531    0.138516  -0.121454  \n",
              " 53     0.005479   -0.598557    0.972493   0.622329  \n",
              " 54     0.176039   -0.503063    1.273927   0.901921  \n",
              " 55    -0.339614   -0.821425    0.480138   0.188663  \n",
              " 56     0.367177   -0.400122    1.568281   1.115926  \n",
              " 57    -0.004847   -0.653838    0.942754   0.604142  \n",
              " 58     1.226998    0.134377    2.910758   2.281282  ,\n",
              " 'jorge_2015_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -5              21  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -6              22  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -4              21  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -5              21  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -4              16  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5      -7              27  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6      -7              24  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7      -4              16  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8      -5              18  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9      -7              25  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10     -6              20  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11     -5              16  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12     -5              20  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13     -7              30  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14     -4              17  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15     -4              14  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16     -4              16  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17     -6              23  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18     -5              21  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19     -5              21  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20     -7              29  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21     -7              28  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22     -4              17  0.244656  0.907786     0.513677   -0.381854   \n",
              " 23     -2              10  1.299719  1.907847     1.132861   -0.306720   \n",
              " 24     -5              19  0.300545  0.971811     0.551178   -0.417529   \n",
              " 25     -4              15  0.016673  0.701026     0.405836   -0.355972   \n",
              " 26     -4              15  0.605856  1.292268     0.767414   -0.334519   \n",
              " 27     -5              22  1.167983  1.820518     1.054672   -0.303858   \n",
              " 28     -4              17  0.481297  1.148127     0.704194   -0.276711   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  \n",
              " 23     2.121856    1.164272    0.669878   0.681651  \n",
              " 24     1.192464    0.540647    0.075988   0.101124  \n",
              " 25     0.928652    0.334020   -0.137238  -0.114068  \n",
              " 26     1.479428    0.766106    0.255104   0.282461  \n",
              " 27     2.008007    1.122259    0.591390   0.595060  \n",
              " 28     1.345654    0.655302    0.162720   0.186917  ,\n",
              " 'lee_2008_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -5              11  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -2              11  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -7              16  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -1              10  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -1               5  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5      -3              12  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6      -4              11  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7      -3              18  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8      -2              12  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9      -4              13  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10     -3               9  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11     -6              15  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12     -3               8  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13     -5              13  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14     -5              13  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15     -3               9  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16     -2              10  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17     -6              13  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18     -4              10  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19     -2              13  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20     -8              17  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21     -5              10  1.540951  2.153551     1.306431   -0.189564   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  ,\n",
              " 'lee_2009_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -6              33  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -2              19  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -2              16  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -4              21  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -4              19  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5      -1               8  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6      -3              20  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7      -7              38  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8      -5              29  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9      -2              16  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10     -2              15  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11     -2              19  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12     -4              26  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13     -4              23  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14     -1               9  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15     -2              19  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16     -2              19  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17     -3              26  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18     -6              30  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19     -2              13  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20     -3              22  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21     -2              14  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22     -2              17  0.244656  0.907786     0.513677   -0.381854   \n",
              " 23     -3              22  1.299719  1.907847     1.132861   -0.306720   \n",
              " 24     -4              23  0.300545  0.971811     0.551178   -0.417529   \n",
              " 25     -2              16  0.016673  0.701026     0.405836   -0.355972   \n",
              " 26     -3              22  0.605856  1.292268     0.767414   -0.334519   \n",
              " 27     -3              16  1.167983  1.820518     1.054672   -0.303858   \n",
              " 28     -2              18  0.481297  1.148127     0.704194   -0.276711   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  \n",
              " 23     2.121856    1.164272    0.669878   0.681651  \n",
              " 24     1.192464    0.540647    0.075988   0.101124  \n",
              " 25     0.928652    0.334020   -0.137238  -0.114068  \n",
              " 26     1.479428    0.766106    0.255104   0.282461  \n",
              " 27     2.008007    1.122259    0.591390   0.595060  \n",
              " 28     1.345654    0.655302    0.162720   0.186917  ,\n",
              " 'salacinski_2012_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -2              23  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -2              26  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -3              27  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -2              26  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -2              19  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5      -2              21  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6      -3              31  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7      -2              26  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8      -2              29  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9      -2              24  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10     -2              21  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11     -1              19  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12     -4              38  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13     -2              19  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14     -3              37  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15     -3              42  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16     -3              43  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17     -2              19  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18     -3              33  0.434524  1.131757     0.682305   -0.362747   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  ,\n",
              " 'wallis_2017_exercise_synthetic':     group  no_of_sessions       age       bmi  pain_before  pain_after  \\\n",
              " 0      -7              17  0.813384 -1.166628    -0.722367    0.255300   \n",
              " 1      -6              16  0.658576 -1.246420    -0.757251    0.180167   \n",
              " 2      -6              17  0.113080 -1.453435    -0.851378   -0.001941   \n",
              " 3      -6              14  0.034694 -1.383480    -0.890929    0.077647   \n",
              " 4      -5              13  1.436030 -1.000350    -0.580358    0.311521   \n",
              " 5      -7              16  2.780974 -0.665643    -0.295337    0.568172   \n",
              " 6      -6              16  1.621174 -0.821288    -0.579563    0.488272   \n",
              " 7      -6              16  2.679129 -0.650577    -0.333156    0.568779   \n",
              " 8      -8              20  0.495571 -1.254436    -0.809606    0.163395   \n",
              " 9      -5              12  1.552913 -0.976088    -0.465756    0.344831   \n",
              " 10     -5              13  2.217002 -0.827488    -0.394187    0.485534   \n",
              " 11     -6              15  2.521886 -0.601416    -0.435643    0.610151   \n",
              " 12     -7              17  0.916683 -1.164214    -0.742798    0.191237   \n",
              " 13     -7              17  1.690567 -0.779442    -0.619338    0.529826   \n",
              " 14     -4              11  0.298908  0.969670     0.558401   -0.359191   \n",
              " 15     -6              15  1.588230  2.195911     1.371051   -0.221007   \n",
              " 16     -7              17  0.229956  0.901930     0.515119   -0.397419   \n",
              " 17     -8              21  0.814848  1.535685     0.908779   -0.345939   \n",
              " 18     -7              17  0.434524  1.131757     0.682305   -0.362747   \n",
              " 19     -8              19  0.766889  1.424478     0.866936   -0.313733   \n",
              " 20     -7              17  0.250997  0.912801     0.492679   -0.403520   \n",
              " 21     -6              14  1.540951  2.153551     1.306431   -0.189564   \n",
              " 22     -8              21  0.244656  0.907786     0.513677   -0.381854   \n",
              " \n",
              "     func_before  func_after  QoL_before  QoL_after  \n",
              " 0     -0.193940    0.156493    0.850382   0.381340  \n",
              " 1     -0.227492    0.060464    0.728915   0.305067  \n",
              " 2     -0.485824   -0.240220    0.303982  -0.043359  \n",
              " 3     -0.547356   -0.216058    0.269809  -0.105836  \n",
              " 4      0.099222    0.418779    1.288035   0.758535  \n",
              " 5      0.779962    1.087691    2.295097   1.640300  \n",
              " 6      0.170831    0.604624    1.464174   0.869244  \n",
              " 7      0.696522    1.000109    2.200258   1.538607  \n",
              " 8     -0.361105   -0.021116    0.600125   0.159100  \n",
              " 9      0.156579    0.467742    1.381841   0.863612  \n",
              " 10     0.465637    0.824258    1.870173   1.267178  \n",
              " 11     0.619283    1.026750    2.137668   1.452470  \n",
              " 12    -0.143252    0.174767    0.889327   0.435297  \n",
              " 13     0.176817    0.610358    1.524982   0.901001  \n",
              " 14     1.179865    0.525708    0.051553   0.075523  \n",
              " 15     2.373719    1.381152    0.854839   0.879371  \n",
              " 16     1.177260    0.491577    0.008988   0.048715  \n",
              " 17     1.720558    0.907500    0.393614   0.415005  \n",
              " 18     1.345520    0.613995    0.146056   0.188427  \n",
              " 19     1.631531    0.861548    0.352177   0.362060  \n",
              " 20     1.172195    0.480915    0.016822   0.033378  \n",
              " 21     2.335258    1.350948    0.808776   0.833921  \n",
              " 22     1.182682    0.496480    0.034361   0.068979  }"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "exercise_dataframes_dict_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now all the data has a mean of 0 and standard deviation of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Added k-fold cross validation\n",
        "\n",
        "As suggested, k-cross fold validation was added. \n",
        "\n",
        "This messes up a little bit with the structure of the code, makes some parts redundant/silly. The code was built to fit a model, and return that fitted model for (possible) later use. Now that the k-fold cross validation is added, several same models are fitted to the differently splitted dataset. Right now the code returns the last one of each iteration. I'm not sure if this is stupid. It might be. It is more complicated to build the code that way, it would have been simpler (and I suppose, the same practically) to just retrain the models again. However, the code is already done and I don't really feel like modifying it, the outcome is same (I think). \n",
        "\n",
        "I had no strong ideas which k value I should pick so I initially chose 10. It apparently has been said to work the best in most cases and is recommended to use if one has no better ideas. However, some of the datasets are so small that the r2 score starts spitting out warnings (I suppose less than 2 data points in one set), so 5 was chosen instead. It seems like a somewhat smart idea, splitting the data 80% for training and 20% testing.\n",
        "\n",
        "https://machinelearningmastery.com/k-fold-cross-validation/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "splits = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3MptJoei82C"
      },
      "source": [
        "## SVM\n",
        "* **Why choose this:** Simply because I'm already familiar with it and it is simple to implement. Also it should work OK with the data.\n",
        "* **Note:** Perhaps should do hyperparameter tuning but that is computationally expensive so not implemented now. Might do that if we get better data. Right now, the data is not good so hyperparameter tuning won't make the results any better so it is just a waste of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LavLipN4i82D"
      },
      "outputs": [],
      "source": [
        "# Function for fitting SVM\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# df is the (exercise group) dataframe being used\n",
        "# cols is the columns we are the predictors (age, bmi and baseline values for pain/funct/QoL)\n",
        "# y is the \"target\" we are trying to \"predict\" (should be either pain_improvement, func_improvement or QoL_improvement)\n",
        "def fit_svm(df, cols, y):\n",
        "    # This here is our data\n",
        "    X = df[cols]\n",
        "    y = df[y]\n",
        "\n",
        "    # Adding k-fold cross validation\n",
        "    kf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        svr = svm.SVR()\n",
        "        svr.fit(X_train, y_train)\n",
        "        y_pred = svr.predict(X_test)\n",
        "        r2 = r2_score(y_test, y_pred)    \n",
        "        scores.append(r2)\n",
        "    \n",
        "    avg_r2 = sum(scores) / len(scores)\n",
        "\n",
        "    return avg_r2, svr\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofV0hpM_i82D"
      },
      "source": [
        "## SVM: Initial data version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Cn_xlXYsi82E"
      },
      "outputs": [],
      "source": [
        "results_svm_dict = {}  # Storing the results and fitted surrogates here\n",
        "\n",
        "# These are the labels, or values we are trying to precit\n",
        "# This is not the cleanest way of doing it, but it is a quick fix.\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "\n",
        "\n",
        "for key in exercise_dataframes_dict.keys():\n",
        "    temp = {}\n",
        "    # Here running through the different options and fitting the surrogate for each option and collecting the info to a dictionary\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, svr = fit_svm(exercise_dataframes_dict[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'svr': svr}\n",
        "    results_svm_dict[key] = temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPzyPAaZi82F"
      },
      "source": [
        "The structure of the dictionary is a bit confusing but should work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dMB0059ei82G",
        "outputId": "0a5c228b-9994-44db-c407-bdb672efea24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pain_after': {'r2': -40.726672969046234, 'svr': SVR()},\n",
              " 'func_after': {'r2': -135.27724017071026, 'svr': SVR()},\n",
              " 'QoL_after': {'r2': -0.7575268793833315, 'svr': SVR()}}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_svm_dict['data_an_2008_exercise']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKI-T2opi82G"
      },
      "source": [
        "## SVM: GAN-generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PveIQrDei82I"
      },
      "outputs": [],
      "source": [
        "results_svm_dict_gan = {}  # Storing the results and fitted surrogates here\n",
        "\n",
        "# These are the labels, or values we are trying to precit\n",
        "# This is not the cleanest way of doing it, but it is a quick fix.\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "\n",
        "for key in exercise_dataframes_dict_gan.keys():\n",
        "    temp = {}\n",
        "    # Here running through the different options and fitting the surrogate for each option and collecting the info to a dictionary\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, svr = fit_svm(exercise_dataframes_dict_gan[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'svr': svr}\n",
        "    results_svm_dict_gan[key] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lRZGW_rfi82I",
        "outputId": "43bfef4c-cc68-4bbd-edea-add355cfedad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pain_after': {'r2': 0.8055397132732599, 'svr': SVR()},\n",
              " 'func_after': {'r2': 0.9694937150186445, 'svr': SVR()},\n",
              " 'QoL_after': {'r2': 0.964048314402189, 'svr': SVR()}}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_svm_dict_gan['an_2008_exercise_synthetic']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKMCUD5Wi82J"
      },
      "source": [
        "# Random forests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* *Why choose it:* It should work OK with the smaller datasets, overfitting shouldn't be an issue\n",
        "* Note: Hyperparameter tuning might have been a good idea, but time ran out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5xNba93ti82K"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def fit_random_forest(df, cols, y):\n",
        "    # This here is our data\n",
        "    X = df[cols]\n",
        "    y = df[y]\n",
        "\n",
        "    # Adding k-fold cross validation\n",
        "    kf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
        "    \n",
        "    scores = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        rf_reg = RandomForestRegressor(n_estimators=5, random_state=42)\n",
        "        rf_reg.fit(X_train, y_train)\n",
        "        y_pred = rf_reg.predict(X_test)\n",
        "        r2 = r2_score(y_test, y_pred)    \n",
        "        scores.append(r2)\n",
        "    \n",
        "    avg_r2 = sum(scores) / len(scores)\n",
        "\n",
        "    return avg_r2, rf_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM5Gu51Ni82K"
      },
      "source": [
        "## RF: Random data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CNNlT9Upi82L"
      },
      "outputs": [],
      "source": [
        "results_forest_reg_dict = {}\n",
        "\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "\n",
        "for key in exercise_dataframes_dict.keys():\n",
        "    temp = {}\n",
        "    # Here running through the different options and fitting the surrogate for each option and collecting the info to a dictionary\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, forest_reg = fit_random_forest(exercise_dataframes_dict[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'forest_reg': forest_reg}\n",
        "    results_forest_reg_dict[key] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mic99ooMi82M",
        "outputId": "a6320a1c-2a25-45e9-a170-dd37175ce373"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=5, random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(n_estimators=5, random_state=42)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the pain_improvement predictor/surrogate function or whatever it is called\n",
        "results_forest_reg_dict['data_cheung_2014_exercise']['pain_after']['forest_reg']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHdZGb6si82O"
      },
      "source": [
        "# RF: GAN-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QTL2dpzni82P"
      },
      "outputs": [],
      "source": [
        "results_forest_reg_dict_gan = {}\n",
        "\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "\n",
        "for key in exercise_dataframes_dict_gan.keys():\n",
        "    temp = {}\n",
        "    # Here running through the different options and fitting the surrogate for each option and collecting the info to a dictionary\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, forest_reg = fit_random_forest(exercise_dataframes_dict_gan[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'forest_reg': forest_reg}\n",
        "    results_forest_reg_dict_gan[key] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Oe7vzkaZi82Q",
        "outputId": "7ba8bb5e-660b-47e0-98aa-4fb01c7dd710"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=5, random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestRegressor(n_estimators=5, random_state=42)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the pain_improvement predictor/surrogate function or whatever it is called\n",
        "results_forest_reg_dict_gan['cheung_2014_exercise_synthetic']['pain_after']['forest_reg']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4b2NGBmuDFg"
      },
      "source": [
        "# Gradient Boosting Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This model is effective for handling regression tasks, especially when dealing with structured tabular data, and normally it provides better performance compared to Random Forests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "JbqfaA12uxBo"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def fit_gradient_boosting(df, cols, y):\n",
        "    X = df[cols]\n",
        "    y = df[y]\n",
        "\n",
        "    # Adding k-fold cross validation\n",
        "    kf = KFold(n_splits=splits, shuffle=True, random_state=42)\n",
        "    \n",
        "    scores = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        gb_reg = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "        gb_reg.fit(X_train, y_train)\n",
        "        y_pred = gb_reg.predict(X_test)\n",
        "        r2 = r2_score(y_test, y_pred)   \n",
        "        scores.append(r2)\n",
        "    \n",
        "    avg_r2 = sum(scores) / len(scores)\n",
        "\n",
        "    return avg_r2, gb_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghjM1aouxk9"
      },
      "source": [
        "## GB Regression: Random data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hd2awgysvQcP"
      },
      "outputs": [],
      "source": [
        "results_gb_dict = {}\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "\n",
        "for key in exercise_dataframes_dict.keys():\n",
        "    temp = {}\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, gb_reg = fit_gradient_boosting(exercise_dataframes_dict[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'gb_reg': gb_reg}\n",
        "    results_gb_dict[key] = temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pain_after': {'r2': -89.0059035630772,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)},\n",
              " 'func_after': {'r2': -294.3005400575695,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)},\n",
              " 'QoL_after': {'r2': -1.3818718309809137,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)}}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "results_gb_dict['data_an_2008_exercise']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxdgU0lhvaTN"
      },
      "source": [
        "## GB Regression: GAN Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3Cdpmoh4veF6"
      },
      "outputs": [],
      "source": [
        "results_gb_dict_gan = {}\n",
        "options = [['pain_before' ,'pain_after'], ['func_before', 'func_after'], ['QoL_before', 'QoL_after']]\n",
        "for key in exercise_dataframes_dict_gan.keys():\n",
        "    temp = {}\n",
        "    for option in options:\n",
        "        features = ['age', 'bmi']\n",
        "        features.append(option[0])\n",
        "        r2, gb_reg = fit_gradient_boosting(exercise_dataframes_dict_gan[key], features, option[1])\n",
        "        temp[option[1]] = {'r2': r2, 'gb_reg': gb_reg}\n",
        "    results_gb_dict_gan[key] = temp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pain_after': {'r2': 0.9162473306035211,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)},\n",
              " 'func_after': {'r2': 0.9760646148810587,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)},\n",
              " 'QoL_after': {'r2': 0.9720286589716214,\n",
              "  'gb_reg': GradientBoostingRegressor(random_state=42)}}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "results_gb_dict_gan['an_2008_exercise_synthetic']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Azvp-9hMi82T"
      },
      "source": [
        "# Tables\n",
        "\n",
        "Here forming tables and printing out the results to be easily viewed. \n",
        "\n",
        "Acquired tables were turned into markdown notation using ChatGPT. Results can be seen below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function for extracting the scores from the dictionaries\n",
        "def extract_scores(results_dict, objectives, dec_places=4):\n",
        "\n",
        "    scores = {obj: [] for obj in objectives}\n",
        "    for key in results_dict:\n",
        "        for obj in objectives:\n",
        "            scores[obj].append(round(results_dict[key][obj]['r2'], dec_places))\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the table\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "def create_pretty_table(therapies, svm_scores, forest_scores, gb_scores, objectives):\n",
        "    table = PrettyTable()\n",
        "    table.add_column('Exercise therapy', therapies)\n",
        "    \n",
        "    for obj in objectives:\n",
        "        table.add_column(f'R2 score SVM {obj.split(\"_\")[0]}', svm_scores[obj])\n",
        "        table.add_column(f'R2 score Forest {obj.split(\"_\")[0]}', forest_scores[obj])\n",
        "        table.add_column(f'R2 score GB {obj.split(\"_\")[0]}', gb_scores[obj])\n",
        "    \n",
        "    return table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crappy data\n",
        "\n",
        "therapies = list(results_svm_dict.keys())\n",
        "objectives = ['pain_after', 'func_after', 'QoL_after']\n",
        "\n",
        "svm_scores = extract_scores(results_svm_dict, objectives)\n",
        "forest_scores = extract_scores(results_forest_reg_dict, objectives)\n",
        "gb_scores = extract_scores(results_gb_dict, objectives)\n",
        "\n",
        "table_init = create_pretty_table(therapies, svm_scores, forest_scores, gb_scores, objectives)\n",
        "\n",
        "# print(table_init)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GAN-data\n",
        "therapies_gan = list(results_svm_dict_gan.keys())\n",
        "objectives = ['pain_after', 'func_after', 'QoL_after']\n",
        "\n",
        "svm_scores_gan = extract_scores(results_svm_dict_gan, objectives)\n",
        "forest_scores_gan = extract_scores(results_forest_reg_dict_gan, objectives)\n",
        "gb_scores_gan = extract_scores(results_gb_dict_gan, objectives)\n",
        "\n",
        "table_gan = create_pretty_table(therapies_gan, svm_scores_gan, forest_scores_gan, gb_scores_gan, objectives)\n",
        "\n",
        "# print(table_gan)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Nrbo9Ui82a"
      },
      "source": [
        "## Random data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Without k-fold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Exercise therapy                | R2 score SVM pain | R2 score Forest pain | R2 score GB pain | R2 score SVM func | R2 score Forest func | R2 score GB func | R2 score SVM QoL | R2 score Forest QoL | R2 score GB QoL |\n",
        "|---------------------------------|-------------------|----------------------|------------------|-------------------|----------------------|------------------|------------------|---------------------|-----------------|\n",
        "| data_an_2008_exercise           | -0.6914           | -0.8982              | -1.5501          | -0.4759           | -1.1577              | -0.2932          | 0.4705           | 0.205               | -0.3348         |\n",
        "| data_cheung_2014_exercise       | -0.1802           | -0.4271              | -0.543           | -0.6104           | -0.8779              | -0.7663          | -3.7761          | -6.1664             | -10.5555        |\n",
        "| data_evcik_2002_exercise1       | -1.0797           | -0.6212              | -0.7551          | -0.756            | -3.4595              | -6.2033          | -0.5791          | -0.7633             | -1.5702         |\n",
        "| data_evcik_2002_exercise2       | -0.8139           | -1.0763              | -1.0567          | 0.24              | -0.1246              | -0.2033          | -0.9896          | -0.414              | -0.9552         |\n",
        "| data_fransen_2001_exercise1     | -0.4017           | -1.0146              | -0.4807          | -0.1789           | -0.431               | -1.0302          | -0.3398          | -0.3302             | -0.3496         |\n",
        "| data_fransen_2001_exercise2     | 0.0448            | -0.32                | -0.4974          | -0.1076           | -0.1192              | -0.4381          | 0.2391           | -0.0358             | 0.008           |\n",
        "| data_jorge_2015_exercise        | -0.6206           | -0.5265              | -0.9307          | -0.1671           | -0.2267              | -0.1905          | -0.5941          | -0.1543             | 0.0318          |\n",
        "| data_lee_2008_exercise          | -0.2755           | -0.4396              | -1.0227          | -0.2289           | -0.7586              | -2.3562          | -1.2375          | -1.1931             | -1.4122         |\n",
        "| data_lee_2009_exercise          | -5.0723           | -4.4588              | -5.5943          | -0.6224           | -0.924               | -1.7738          | -0.0384          | 0.2447              | -0.16           |\n",
        "| data_salacinski_2012_exercise   | -0.7618           | -0.7855              | -0.6074          | -2.0316           | -1.8753              | -2.577           | -3.1592          | -3.4713             | -4.3074         |\n",
        "| data_wallis_2017_exercise       | -0.4665           | -0.3142              | -0.0839          | -0.3792           | -0.7595              | -0.6224          | -0.228           | -0.8155             | -0.3191         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With k-fold cross validation\n",
        "\n",
        "*Insert table*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3DfOTX7i82b"
      },
      "source": [
        "## GAN-generated data\n",
        "\n",
        "### Without k-fold cross validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Exercise therapy                   | R2 score SVM pain | R2 score Forest pain | R2 score GB pain | R2 score SVM func | R2 score Forest func | R2 score GB func | R2 score SVM QoL | R2 score Forest QoL | R2 score GB QoL |\n",
        "|------------------------------------|-------------------|----------------------|------------------|-------------------|----------------------|------------------|------------------|---------------------|-----------------|\n",
        "| an_2008_exercise_synthetic         | 0.9444            | 0.843                | 0.9129           | 0.9012            | 0.837                | 0.9607           | 0.9175           | 0.942               | 0.967           |\n",
        "| cheung_2014_exercise_synthetic     | 0.4373            | 0.3909               | -0.0049          | 0.9205            | 0.9412               | 0.993            | 0.9224           | 0.9236              | 0.9731          |\n",
        "| evcik_2002_exercise1_synthetic     | 0.9707            | 0.971                | 0.9237           | 0.9911            | 0.9333               | 0.986            | 0.9928           | 0.98                | 0.9872          |\n",
        "| evcik_2002_exercise2_synthetic     | 0.938             | 0.9343               | 0.92             | 0.9672            | 0.9327               | 0.934            | 0.9789           | 0.9705              | 0.9457          |\n",
        "| fransen_2001_exercise1_synthetic   | 0.8766            | 0.8507               | 0.9096           | 0.925             | 0.9397               | 0.9496           | 0.6551           | 0.6208              | 0.3682          |\n",
        "| fransen_2001_exercise2_synthetic   | 0.4964            | 0.5691               | 0.43             | 0.9758            | 0.9746               | 0.99             | 0.9899           | 0.9945              | 0.9947          |\n",
        "| jorge_2015_exercise_synthetic      | 0.7986            | 0.8563               | 0.7469           | 0.8913            | 0.8689               | 0.8795           | 0.9805           | 0.973               | 0.9831          |\n",
        "| lee_2008_exercise_synthetic        | 0.8163            | 0.9184               | 0.9437           | 0.7472            | 0.8436               | 0.857            | 0.8743           | 0.9459              | 0.9398          |\n",
        "| lee_2009_exercise_synthetic        | 0.9397            | 0.9064               | 0.9472           | 0.9673            | 0.6264               | 0.7381           | 0.912            | 0.8836              | 0.8267          |\n",
        "| salacinski_2012_exercise_synthetic | 0.6327            | 0.3144               | 0.3275           | 0.0207            | -0.8448              | -0.4018          | 0.9288           | 0.9506              | 0.9681          |\n",
        "| wallis_2017_exercise_synthetic     | 0.832             | 0.7696               | 0.7762           | 0.9279            | 0.9648               | 0.9848           | 0.9181           | 0.9662              | 0.9827          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With k-fold cross validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "|          Exercise therapy          | R2 score SVM pain | R2 score Forest pain | R2 score GB pain | R2 score SVM func | R2 score Forest func | R2 score GB func | R2 score SVM QoL | R2 score Forest QoL | R2 score GB QoL |\n",
        "|------------------------------------|-------------------|----------------------|------------------|-------------------|----------------------|------------------|------------------|---------------------|-----------------|\n",
        "| an_2008_exercise_synthetic         | 0.8895            | 0.774                | 0.9132           | 0.9438            | 0.9165               | 0.9741           | 0.9409           | 0.9102              | 0.9746          |\n",
        "| cheung_2014_exercise_synthetic     | 0.1756            | 0.1753               | 0.0589           | 0.8971            | 0.8589               | 0.9492           | 0.8766           | 0.769               | 0.9268          |\n",
        "| evcik_2002_exercise1_synthetic     | 0.8955            | 0.9222               | 0.9465           | 0.925             | 0.9433               | 0.9817           | 0.9313           | 0.9626              | 0.9833          |\n",
        "| evcik_2002_exercise2_synthetic     | 0.6993            | 0.8696               | 0.8724           | 0.7243            | 0.878                | 0.8859           | 0.7227           | 0.9                 | 0.906           |\n",
        "| fransen_2001_exercise1_synthetic   | 0.8108            | 0.8571               | 0.78             | 0.8313            | 0.9424               | 0.9356           | 0.3113           | 0.1341              | 0.264           |\n",
        "| fransen_2001_exercise2_synthetic   | 0.3535            | 0.1099               | 0.1626           | 0.9716            | 0.9695               | 0.9869           | 0.9859           | 0.9917              | 0.9921          |\n",
        "| jorge_2015_exercise_synthetic      | 0.3629            | 0.3748               | 0.2732           | 0.7996            | 0.8586               | 0.8757           | 0.8988           | 0.957               | 0.9678          |\n",
        "| lee_2008_exercise_synthetic        | 0.81              | 0.9303               | 0.9072           | 0.8157            | 0.8078               | 0.7279           | 0.8296           | 0.9082              | 0.9181          |\n",
        "| lee_2009_exercise_synthetic        | 0.798             | 0.8724               | 0.8953           | 0.7734            | 0.2987               | 0.6166           | 0.8376           | 0.6361              | 0.7979          |\n",
        "| salacinski_2012_exercise_synthetic | -0.5823           | -3.2075              | -1.2542          | -0.1042           | -0.8307              | -0.5536          | 0.9498           | 0.9273              | 0.9407          |\n",
        "| wallis_2017_exercise_synthetic     | 0.3657            | 0.2783               | 0.4045           | 0.9219            | 0.8444               | 0.8835           | 0.9451           | 0.8699              | 0.9218          |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What to do with results that aren't good?\n",
        "\n",
        "We can see above, that salacinski, for example is giving shit results. So is, for example,  cheung in pain score prediction. Not sure what should be done. In an ideal case, new surrogates would be fit and se if results would get better. If not, then a closer look would be taken into the data. Plotting should and could work to see if there is something happening that the models arent picking up on. Perhaps the k fold cross validation was dumbly implemented, perhaps the splits should have been fewer/more. Because time is almost out with this project, choosing to remove all the lines with crap results, even if that means in one objective only. Crap R2 score is here defined to be under 0.6. \n",
        "\n",
        "This leaves us only 5 therapies in total left for implementing the problem. This is not ideal, this way many excellent therapy alternatives are ruled out. However, workload wise it works in our favour - less things for us to implement!\n",
        "\n",
        "We have left: \n",
        "* an\n",
        "* evcik 1 and 2\n",
        "* both lees (2008 and 2009)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Picking the best performing surrogates\n",
        "\n",
        "Here yada yada about which surrogate performed best for each dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Question\n",
        "\n",
        "Would it be better to predict after intervention scores or the improvement percentage?\n",
        "\n",
        "After a quick experiment, it seems that (for GAN data) surrogates perform better when predicting after scores compared to predicting improvement percentage. \n",
        "\n",
        "If we were to predict improvement, forming the objectives would be simpler, since the predictor would give the percentage straight up. If we predict the after score, percentage would have to be calculated, but that is not such a big deal? Just needs some extra work. So rolling with the predicting after scores thing. Need to remember to yada yada about this in the final report also!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Checking that the keys are the same for all results dics\n",
        "print(results_svm_dict_gan.keys() == results_gb_dict_gan.keys())\n",
        "print(results_svm_dict_gan.keys() == results_forest_reg_dict_gan.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This picks out the best performing surrogate predictor for each study\n",
        "# Results stored: How?\n",
        "\n",
        "# These are all surrogate results\n",
        "results = [results_svm_dict_gan, results_forest_reg_dict_gan, results_gb_dict_gan]\n",
        "\n",
        "# Keys are the same for all\n",
        "keys = results_gb_dict_gan.keys()\n",
        "\n",
        "# Keys to different scores/objectives\n",
        "objectives = ['pain_after', 'func_after', 'QoL_after']\n",
        "\n",
        "# Loop keys, then loop score type/objectives, THEN FINALL\n",
        "# Y loop all results, check which method has the best R2 score, pick that predictor. Stuff all\n",
        "best_surrogates = {'pain_after': [], 'func_after': [], 'QoL_after': [] }\n",
        "for key in keys:\n",
        "    for obj in objectives:\n",
        "        # List comprehension: get the values\n",
        "        vals = [x[key][obj] for x in results]\n",
        "\n",
        "        # Here we choose the surrogate with the best r2 score\n",
        "        best = max(vals, key=lambda x: x['r2'])\n",
        "        # print(best)\n",
        "\n",
        "        # Get the key to the surrogate model (in hidsight, should have done this in a better way earlier in code)\n",
        "        key_to_surr = list(best.keys())[1]\n",
        "\n",
        "        # Add to the correct list\n",
        "        best_surrogates[obj].append({key: best[key_to_surr]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Picking out the groups for implementing the problem. \n",
        "def filter_exercise_groups(data, keywords):\n",
        "    filtered_data = {key: [] for key in data.keys()}\n",
        "    for key, models in data.items():\n",
        "        for model_dict in models:\n",
        "            for group_name in model_dict.keys():\n",
        "                # Extract the part of the group name before the first underscore\n",
        "                prefix = group_name.split('_')[0]\n",
        "                if prefix in keywords:\n",
        "                    filtered_data[key].append(model_dict)\n",
        "    \n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "obj_dict = filter_exercise_groups(best_surrogates, ['an', 'lee', 'evcik'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pain_after': [{'an_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'evcik_2002_exercise1_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'evcik_2002_exercise2_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2009_exercise_synthetic': GradientBoostingRegressor(random_state=42)}],\n",
              " 'func_after': [{'an_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'evcik_2002_exercise1_synthetic': SVR()},\n",
              "  {'evcik_2002_exercise2_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2009_exercise_synthetic': GradientBoostingRegressor(random_state=42)}],\n",
              " 'QoL_after': [{'an_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'evcik_2002_exercise1_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'evcik_2002_exercise2_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2008_exercise_synthetic': GradientBoostingRegressor(random_state=42)},\n",
              "  {'lee_2009_exercise_synthetic': GradientBoostingRegressor(random_state=42)}]}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have all the best surrogates extracted, we use those to construct the objective function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 1.4463658 , -0.33191303, -0.24234167, -0.36454112,  0.63095941]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = np.array([89, 24, 8.9, 20, 65])\n",
        "data = data.reshape(1, -1)\n",
        "f_scaler_gan.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_surrogates['pain_after']  # this is a list of dictionaries\n",
        "surr_an = best_surrogates['pain_after'][0]['an_2008_exercise_synthetic'] # this is messy, but it works. \n",
        "\n",
        "# # TODO: pretty sure this is not correct, need to figure out when i have more time\n",
        "# # output should change when input does but it stays the same. I don't know what the hell is going on\n",
        "# # ITS ABOUT NORMALIZATION I THINK!! We need to scale the data before we add it in and the output needs to be rescaled back.\n",
        "\n",
        "data = np.array([89, 24, 8.9, 20, 65])\n",
        "data = data.reshape(1, -1)\n",
        "data_scaled = f_scaler_gan.transform(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhzpf8vWi82d"
      },
      "source": [
        "# Problem formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rj0BhWRi82e"
      },
      "source": [
        "### Preferences provided by the DM in the original paper\n",
        "Acceptable minimum and maximum ranges for the objectives (**Can't use it exactly like this, need to modify**)\n",
        "\n",
        "| |Costs (€) | Pain change (%) | Function change (%) | Supervised sessions | Period (weeks) |\n",
        "| -------|------------|------------------|----------------------|----------------------|----------------|\n",
        "| Iteration 1 | 300 | +30% | +25% | 0 | 8 |\n",
        "| | 600 | +15% | +15% | 15 | 26 |\n",
        "| Iteration 2  | 200 | +25% | +40% | 0 | 12 |\n",
        "| | 500 | +15% | +15% | 30 | 26 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ePOOeR4pNb"
      },
      "source": [
        "Suggestion by P as DM (Didn't change much):\n",
        "\n",
        "| |Costs (€) | Pain change (%) | Function change (%) | Supervised sessions | Period (weeks) |\n",
        "| -------|------------|------------------|----------------------|----------------------|----------------|\n",
        "| Iteration 1 | 200 | +30% | +25% | 0 | 8 |\n",
        "| | 800 | +15% | +15% | 15 | 24 |\n",
        "| Iteration 2  | 150 | +25% | +40% | 0 | 12 |\n",
        "| | 600 | +15% | +15% | 20 | 24 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reference point method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here for easy access the keys to each surrogate model in the obj_dict\n",
        "\n",
        "an = 'an_2008_exercise_synthetic'\n",
        "evcik1 = 'evcik_2002_exercise1_synthetic'\n",
        "evcik2 = 'evcik_2002_exercise2_synthetic'\n",
        "lee1 = 'lee_2008_exercise_synthetic'\n",
        "lee2 = 'lee_2009_exercise_synthetic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from desdeo_problem import variable_builder\n",
        "\n",
        "# Variables defined here. TODO: Figure out how to make the problem binary.\n",
        "# Variables: x1 = an, x2 = evcik1, x3 = evcik2, x4 = lee_2008, x5 = lee_2009\n",
        "# Variable value is one if the therapy is chosen, otherwise 0. Only one can be chosen. \n",
        "\n",
        "var_names = list(['x1', 'x2', 'x3', 'x4', 'x5'])\n",
        "\n",
        "# Starting with no exercise therapy chosen\n",
        "initial_values = [0, 0, 0, 0, 0]  \n",
        "\n",
        "lower_bounds = [0] * len(var_names) \n",
        "upper_bounds = [1] * len(var_names)\n",
        "\n",
        "variables = variable_builder(var_names, initial_values, lower_bounds, upper_bounds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vars = [age, bmi, pain_before, func_before, qol_before]\n",
        "# Just setting some variable values. This is the patient info. \n",
        "# This imaginary patient is 89 years old, has a BMI of 34 and has the baseline scores for pain, function and QoL as 8, 15 and 67 respectively. \n",
        "vars = [89, 34, 8, 15, 67]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# x is the variables of the problem.\n",
        "\n",
        "def obj_pain(xs):\n",
        "    data = np.array(vars)\n",
        "\n",
        "    data = data.reshape(1, -1) \n",
        "    data_scaled = f_scaler_gan.transform(data)\n",
        "\n",
        "    # Pick out the relevant info for the surrogates. \n",
        "    surr_input = np.array([data_scaled[0][0], data_scaled[0][1], data_scaled[0][2]])\n",
        "    surr_input = surr_input.reshape(1, -1)\n",
        "\n",
        "    # Need to pick out the pain surrogate functions from the dictionary\n",
        "    surrogates = [list(d.values())[0] for d in obj_dict['pain_after']]\n",
        "\n",
        "    # Feeding the scaled data to the functions to get the prediction for the improvement value.\n",
        "    scaled_predictions = [surrogate.predict(surr_input) for surrogate in surrogates]\n",
        "\n",
        "    # Unscaling the predictions\n",
        "    predictions = [pain_scaler_gan.inverse_transform(p.reshape(1,-1)) for p in scaled_predictions]\n",
        "    \n",
        "    # Uncomplicate the predictions layout to a simple list of values\n",
        "    predictions_list = [prediction[0][0] for prediction in predictions]\n",
        "\n",
        "    before = vars[2]\n",
        "\n",
        "    # Now we can actually start forming the objective function. First calculate the improvement in percentages for each\n",
        "    improvements = [(before - after)/before * 100 for after in predictions_list]\n",
        "\n",
        "    # Returning negated becacuse this objective is to be maximized and by default ref point method minimizes\n",
        "    return - sum(x * i for x, i in zip(xs, improvements))\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-47.83581547841121"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_pain([0,0,1,0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vars = [age, bmi, pain_before, func_before, qol_before]\n",
        "# x is the variables of the problem.\n",
        "\n",
        "def obj_func(xs):\n",
        "    data = np.array(vars)\n",
        "\n",
        "    data = data.reshape(1, -1) \n",
        "    data_scaled = f_scaler_gan.transform(data)\n",
        "\n",
        "    # Pick out the relevant info for the surrogates. \n",
        "    surr_input = np.array([data_scaled[0][0], data_scaled[0][1], data_scaled[0][3]])\n",
        "    surr_input = surr_input.reshape(1, -1)\n",
        "\n",
        "    # Need to pick out the func surrogate functions from the dictionary\n",
        "    surrogates = [list(d.values())[0] for d in obj_dict['func_after']]\n",
        "\n",
        "    # Feeding the scaled data to the functions to get the prediction for the improvement value.\n",
        "    scaled_predictions = [surrogate.predict(surr_input) for surrogate in surrogates]\n",
        "\n",
        "    # Unscaling the predictions\n",
        "    predictions = [func_scaler_gan.inverse_transform(p.reshape(1,-1)) for p in scaled_predictions]\n",
        "    \n",
        "    # Uncomplicate the predictions layout to a simple list of values\n",
        "    predictions_list = [prediction[0][0] for prediction in predictions]\n",
        "\n",
        "    before = vars[3]\n",
        "\n",
        "    # Now we can actually start forming the objective function. First calculate the improvement in percentages for each\n",
        "    improvements = [(before - after)/before * 100 for after in predictions_list]\n",
        "\n",
        "    return - sum(x * i for x, i in zip(xs, improvements))\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "80.63041368902901"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_func([0,0,0,0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vars = [age, bmi, pain_before, func_before, qol_before]\n",
        "# x is the variables of the problem.\n",
        "\n",
        "def obj_qol(xs):\n",
        "    data = np.array(vars)\n",
        "\n",
        "    data = data.reshape(1, -1) \n",
        "    data_scaled = f_scaler_gan.transform(data)\n",
        "\n",
        "    # Pick out the relevant info for the surrogates. \n",
        "    surr_input = np.array([data_scaled[0][0], data_scaled[0][1], data_scaled[0][4]])\n",
        "    surr_input = surr_input.reshape(1, -1)\n",
        "\n",
        "    # Need to pick out the func surrogate functions from the dictionary\n",
        "    surrogates = [list(d.values())[0] for d in obj_dict['QoL_after']]\n",
        "\n",
        "    # Feeding the scaled data to the functions to get the prediction for the improvement value.\n",
        "    scaled_predictions = [surrogate.predict(surr_input) for surrogate in surrogates]\n",
        "\n",
        "    # Unscaling the predictions\n",
        "    predictions = [qol_scaler_gan.inverse_transform(p.reshape(1,-1)) for p in scaled_predictions]\n",
        "    \n",
        "    # Uncomplicate the predictions layout to a simple list of values\n",
        "    predictions_list = [prediction[0][0] for prediction in predictions]\n",
        "\n",
        "    before = vars[4]\n",
        "\n",
        "    # Now we can actually start forming the objective function. First calculate the improvement in percentages for each\n",
        "    improvements = [(after-before)/before * 100 for after in predictions_list]\n",
        "\n",
        "    return - sum(x * i for x, i in zip(xs, improvements))\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\omistaja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-28.173738271881692"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_qol([0,0,0,1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Objectives \n",
        "from desdeo_problem import _ScalarObjective\n",
        "from desdeo_problem import MOProblem\n",
        "\n",
        "objective1 = _ScalarObjective(name=\"f1\", evaluator= obj_pain)\n",
        "objective2 = _ScalarObjective(name=\"f2\", evaluator= obj_func)\n",
        "objective3 = _ScalarObjective(name=\"f3\", evaluator= obj_qol)\n",
        "\n",
        "# Problem implementation\n",
        "problem = MOProblem(objectives=[objective1, objective2, objective3], variables=variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Just some values, cutting corners here. Should (and could) find out the real values but need to test if the problem is implemented OK!\n",
        "nadir = np.array([100, 100, 100])\n",
        "ideal = np.array([-100, -100, -100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ideal:  [-100 -100 -100]\n",
            "Nadir:  [100 100 100]\n"
          ]
        }
      ],
      "source": [
        "from desdeo_mcdm.interactive.ReferencePointMethod import ReferencePointMethod\n",
        "\n",
        "method = ReferencePointMethod(problem, ideal, nadir)\n",
        "\n",
        "\n",
        "# Ideal and nadir \"backwards\" because the original obj fucntions need to be maximized but by ref point method minimizes.\n",
        "print(\"Ideal: \", ideal)\n",
        "print(\"Nadir: \", nadir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Please specify a reference point as 'reference_point'.\""
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "request = method.start()\n",
        "\n",
        "request.content['message']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First reference point. We want 30% improvement in pain, 15 in function and 20 in QoL.\n",
        "ref_point = [30, 15, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "reference_point = np.array(ref_point)\n",
        "\n",
        "# Adding the reference\n",
        "request.response = {'reference_point': reference_point}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Why won't this woooorkkk.. I give up...\n",
        "# request = method.iterate(request)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Different approach (?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install desdeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "MFRTP01C53Qf"
      },
      "outputs": [],
      "source": [
        "# #I did not run the code and it seems colab has an issue of loading synthetic data\n",
        "\n",
        "# #Just Seperate Implementation using DESDEO\n",
        "# from desdeo.problem import ScalarDataProblem, ScalarMOProblem\n",
        "# from desdeo.variables import variable_builder\n",
        "# from desdeo.metrics import Hypervolume\n",
        "\n",
        "# ranges_iteration_1 = [\n",
        "#     (200, 800),    # Costs (€)\n",
        "#     (30, 15),      # Pain change (%)\n",
        "#     (25, 15),      # Function change (%)\n",
        "#     (0, 15),       # Supervised sessions\n",
        "#     (8, 24)        # Period (weeks)\n",
        "# ]\n",
        "\n",
        "# ranges_iteration_2 = [\n",
        "#     (150, 600),    # Costs (€)\n",
        "#     (25, 15),      # Pain change (%)\n",
        "#     (40, 15),      # Function change (%)\n",
        "#     (0, 20),       # Supervised sessions\n",
        "#     (12, 24)       # Period (weeks)\n",
        "# ]\n",
        "\n",
        "# # Bit changed from orginal paper\n",
        "# variable_type = [\"int\", \"float\", \"float\", \"int\", \"int\"]\n",
        "# variable_ranges = [(150, 800), (-30, 30), (-30, 30), (0, 20), (8, 24)]\n",
        "\n",
        "# problem_iteration_1 = ScalarDataProblem(variable_builder(variable_type, variable_ranges),\n",
        "#                                         [\"Costs (€)\", \"Pain change (%)\", \"Function change (%)\",\n",
        "#                                          \"Supervised sessions\", \"Period (weeks)\"],\n",
        "#                                         [\"minimize\", \"minimize\", \"minimize\", \"minimize\", \"minimize\"],\n",
        "#                                         variables_description=[\"Costs associated with the therapy\",\n",
        "#                                                                \"Percentage change in pain\",\n",
        "#                                                                \"Percentage change in function\",\n",
        "#                                                                \"Number of supervised sessions\",\n",
        "#                                                                \"Duration of therapy in weeks\"],\n",
        "#                                         ideal=[200, 30, 25, 0, 8],\n",
        "#                                         nadir=[800, 15, 15, 15, 24],\n",
        "#                                         constraints=ranges_iteration_1)\n",
        "\n",
        "# problem_iteration_2 = ScalarDataProblem(variable_builder(variable_type, variable_ranges),\n",
        "#                                         [\"Costs (€)\", \"Pain change (%)\", \"Function change (%)\",\n",
        "#                                          \"Supervised sessions\", \"Period (weeks)\"],\n",
        "#                                         [\"minimize\", \"minimize\", \"minimize\", \"minimize\", \"minimize\"],\n",
        "#                                         variables_description=[\"Costs associated with the therapy\",\n",
        "#                                                                \"Percentage change in pain\",\n",
        "#                                                                \"Percentage change in function\",\n",
        "#                                                                \"Number of supervised sessions\",\n",
        "#                                                                \"Duration of therapy in weeks\"],\n",
        "#                                         ideal=[150, 25, 40, 0, 12],\n",
        "#                                         nadir=[600, 15, 15, 20, 24],\n",
        "#                                         constraints=ranges_iteration_2)\n",
        "\n",
        "\n",
        "# problems = [problem_iteration_1, problem_iteration_2]\n",
        "# scalar_mo_problem = ScalarMOProblem(problems)\n",
        "\n",
        "# hypervolume_metric = Hypervolume(scalar_mo_problem)\n",
        "\n",
        "# # Can change algorithm. Just used NSGA2\n",
        "# from desdeo.optimizers.NSGA2 import NSGA2\n",
        "\n",
        "# optimizer = NSGA2(scalar_mo_problem)\n",
        "\n",
        "# n_iterations = 100\n",
        "# approximation = optimizer.minimize(n_iterations)\n",
        "\n",
        "# for i, problem in enumerate(problems):\n",
        "#     print(f\"Iteration {i+1}:\")\n",
        "#     print(f\"  Number of solutions: {len(approximation.objectives[i])}\")\n",
        "#     print(f\"  Hypervolume: {hypervolume_metric(approximation.objectives[i])}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
