{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting the Excel: Assumptions and stuff\n",
    "* Copied only vital information for the data generation.\n",
    "* Everything is in its own cell, so easy to import into a pandas dataframe. \n",
    "* Study number five (Jorge, 2015) had measurements for 6- and 12-week checkpoints for Pain, Function and QoL. Only 12 was added to the new excel, since assumedly that is the duration of the treatment/therapy. \n",
    "* O'Reilly paper was removed since they reported only the change in QoL, not the actual baseline value. Can't calculate the percentages based on just that.\n",
    "* Fransen paper has reported the WOMAC scores as inverse, so 0 represents the worst status and 100 the best. Might be that others have done that too \n",
    "    * _The WOMAC scores were reverse scored (100 = no pain\n",
    "or difficulty, 0 = extreme pain or difficulty), so that for all outcome measures higher scores are better scores._ https://www.jrheum.org/content/jrheum/28/1/156.full.pdf (That has been adjusted to the project_excel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Group:\n",
    "    * Used 1 - exercise and 0 - control because it is also using in the objective functions\n",
    "\n",
    "* No of sessions:\n",
    "    * Also added because it is using in the objective functions\n",
    "    * 0 used for control assuming control fact do not have any sessions\n",
    "\n",
    "* Age:\n",
    "    * several different \"value types\" in paranthesis\n",
    "    * for some there is the +/- notation: not sure what that means. Need to assume something but what?\n",
    "    * for those cells with input like 71.9 (69.3, 74.6), in the paranthesis seems to be the 95% CI (only checked Cheung paper)\n",
    "    * for some there is mean (SD) notation used, SD being standard deviation\n",
    "    * According to the Wallis paper age structure may be Age_Mean_value (Age_SD)\n",
    "    * According to the Evcik paper the +/- notation follows SD\n",
    "    * There is a problem with entering decimal numbers. So I replaced . with , and changed the font color in red\n",
    "\n",
    "* BMI: \n",
    "    * same issues as with age\n",
    "\n",
    "\n",
    "* Study participants/subjects:\n",
    "    * for simplicity's sake, it was assumed that all participants finished the therapies/participating in the study. (In reality this is not true, but cutting corners here a little bit, this is already getting out of hand)\n",
    "\n",
    "    * Do we need to keep Male and Female separate?  - _I don't think so. The information is not used in any of the objectives or in the data later, all the numbers are for the genders combined. Ideally, we should take the gender into account, but I think it is just complicating matters at this point. -J_\n",
    "\n",
    "* Pain levels:\n",
    "    * only the womac score included\n",
    "    * unless otherwise mentioned, it was assumed that the score was 0-20\n",
    "    * notice: not all were in the same scale, so needed to scale\n",
    "    * WOMAC (35 pain) don't know what this means and can't get access to the article to check so not doing anything to the values\n",
    "    * 'changes' was interpreted to mean how much the original womac value changed, so the 'after' value would baseline+change.\n",
    "\n",
    "\n",
    "* Functionality\n",
    "    * can't get access to check what womac fc 85 means so leaving that as is (since googling didn't help either)\n",
    "\n",
    "    \n",
    "* QoL\n",
    "    * different tests were used to test quality of life. If the scales were same, it was assumemd that they are comparable as is. \n",
    "    * everything was scaled to 0-100\n",
    "    * assuming that NHP emotional reaction is scaled from 0-100\n",
    "    * should maybe check if all scores are the \"same order\", like 0 is worst in all and 100 best. (Because for example for NHP: \"the total score for each domain is 100 where a score of 0 indicates good subjective health status and 100 indicates poor subjective health status.\" and I think SF-36 might use the scale the other way, 0 being worst and 100 being best)\n",
    "        * assuming 100 is the best score and 0 the worst\n",
    "        * I inversed the last study's QoL scores since they were the wrong way around (0 being the best and 100 worst) \n",
    "        * assuming others are OK, since the numbers make sense (they are rising after intervention/with time)\n",
    "    * Also for one paper there is no values, what should be done with that? (marked in grey) \n",
    "        * _This study has been dropped._\n",
    "    * **In the final report we shouold mention that several different metrics were used and that they might not be comparable**\n",
    "        * Although in theory, since we are comparing the change (or the percentage of improvement), they might not be that different?\n",
    "\n",
    "\n",
    "Color coding for the half finished table: \n",
    "* pink: need to somehow turn values into standard deviation\n",
    "* green: need to find out what mm means and turn the value into scores (need to read the source paper)\n",
    "\n",
    "\n",
    "\n",
    "_TODO: add table columns and explain them_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install desdeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation\n",
    "* Find a method that can generate artificial data based on mean and variance\n",
    "* If a method cannot be found, need to assume distriubtion\n",
    "    * Example of normally distributed data generation below (with mean and variance)\n",
    "    * Compare that to some existing data (if there is such) \n",
    "        * if looks good, run with it\n",
    "        * but what if it does not look good? And if there is existing data, wouldn't it be easier to generate synthetic data based on that? There's ways to generate \"anonymous\" (synthetic) data from existing patient information, so that no patient confidiality is broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to generate data for\n",
    "* Age \n",
    "    * assumption: distribution probably skewed to the older side, since it is knee OA (older people more likely to have it)\n",
    "    * modeled as normal distribution, should maybe skew it a bit to the older side?\n",
    "* BMI \n",
    "    * Knee osteoarthiritis and bmi connected, could use that information?  https://www.sciencedirect.com/science/article/abs/pii/S1297319X11001370\n",
    "    * modeled as a normal distribution, should skew it somehow maybe?\n",
    "* Pain (baseline)\n",
    "    * modeled as normal distribution for now (same for all the rest - should probably think more)\n",
    "* Physical Functionality (baseline)\n",
    "* QoL (baseline)\n",
    "* Pain (after intervention)\n",
    "* Physical Functionality (after intervention)\n",
    "* QoL (after intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the excel into a dataframe\n",
    "df = pd.read_excel('project_excel.xlsx', index_col='reference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation: normally distributed\n",
    "\n",
    "All generated data is stored in a dictionary, where the first column in excel (or the df index row) is the key and its value is another dataframe of the form \n",
    "\n",
    "\n",
    "{ <br>\n",
    "        'age': data_age, <br>\n",
    "        'bmi': data_bmi, <br>\n",
    "        'patients_num': num_of_participants,<br>\n",
    "        'pain_before': pain_before_data,<br>\n",
    "        'pain_after': pain_after_data,<br>\n",
    "        'functionality_before': func_before_data,<br>\n",
    "        'functionality_after': func_after_data,<br>\n",
    "        'QoL_before': qol_before_data,<br>\n",
    "        'QoL_after': qol_after_data<br>\n",
    "}\n",
    "\n",
    "\n",
    "*If we have time to do another version of the data generation, that could probably be done with just copy pasting this version.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** \n",
    " * pain on scale 0-20 (0 meaning no pain and being the best value)\n",
    "    * so pain_after should be assumed to be smaller than pain_before and calculating the percentage as (before-after)/before * 100\n",
    " * function 0-68 (0 being the best)\n",
    "    * percentage calculated as above\n",
    " * QoL on scale 0-100, the bigger the better.\n",
    "    * value is assumed to get higher after intervention/with time, so calculating the percentage as (after-before)/before * 100\n",
    "\n",
    "*Note: If the percentage values are negative, it means the improvement has been negative.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes the whole column as input, divides it into pairs with the relevant mean and std \n",
    "# except the number of participants in the study is just an integer.\n",
    "# Then generates the data based on the above distributions and returns it in a dictionary \n",
    "def generate_data(info):\n",
    "    age = (info['age_mean'], info['age_std'])\n",
    "    bmi = (info['bmi_mean'], info['bmi_std'])\n",
    "    num_of_participants = int(info['num_of_subjects'])\n",
    "    pain_before = (info['pain_before_mean'], info['pain_before_std'])\n",
    "    pain_after = (info['pain_after_mean'], info['pain_after_std'])\n",
    "    func_before = (info['func_before_mean'], info['func_before_std'])\n",
    "    func_after = (info['func_after_mean'], info['func_after_std'])\n",
    "    qol_before = (info['QoL_before_mean'], info['QoL_before_std'])\n",
    "    qol_after = (info['QoL_after_mean'], info['QoL_after_std'])\n",
    "\n",
    "    # Generating the data\n",
    "    data_age = np.random.normal(age[0], age[1], num_of_participants)\n",
    "    data_bmi = np.random.normal(bmi[0], bmi[1], num_of_participants)\n",
    "    pain_before_data = np.random.normal(pain_before[0], pain_before[1], num_of_participants)\n",
    "    pain_after_data = np.random.normal(pain_after[0], pain_after[1], num_of_participants)\n",
    "    func_before_data = np.random.normal(func_before[0], func_before[1], num_of_participants)\n",
    "    func_after_data = np.random.normal(func_after[0], func_after[1], num_of_participants)\n",
    "    qol_before_data = np.random.normal(qol_before[0], qol_before[1], num_of_participants)\n",
    "    qol_after_data = np.random.normal(qol_after[0], qol_after[1], num_of_participants)\n",
    "\n",
    "    # Calculating the improvement percent for each patient (pain, function and QoL)\n",
    "    pain_improvement = (pain_before_data - pain_after_data)/pain_before_data * 100\n",
    "    func_improvement = (func_before_data - func_after_data)/func_before_data * 100\n",
    "    qol_improvement = (qol_after_data - qol_before_data)/qol_before_data * 100\n",
    "\n",
    "    return {\n",
    "        'age': data_age,\n",
    "        'bmi': data_bmi,\n",
    "        'patients_num': num_of_participants,\n",
    "        'pain_before': pain_before_data,\n",
    "        'pain_after': pain_after_data,\n",
    "        'pain_improvement': pain_improvement,\n",
    "        'func_before': func_before_data,\n",
    "        'func_after': func_after_data,\n",
    "        'func_improvement': func_improvement,\n",
    "        'QoL_before': qol_before_data,\n",
    "        'QoL_after': qol_after_data,\n",
    "        'QoL_improvement': qol_improvement\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for creating csv files for each exercise and control group\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def write_to_csv(data, filename, folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    with open(filepath, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['age', 'bmi', 'pain_before', 'pain_after', 'pain_improvement',\n",
    "                         'func_before', 'func_after', 'func_improvement', 'QoL_before', 'QoL_after', 'QoL_improvement'])\n",
    "    \n",
    "        for i in range(data['patients_num']):\n",
    "            writer.writerow([data['age'][i], data['bmi'][i], \n",
    "                             data['pain_before'][i], data['pain_after'][i], data['pain_improvement'][i], \n",
    "                             data['func_before'][i], data['func_after'][i], data['func_improvement'][i], \n",
    "                             data['QoL_before'][i], data['QoL_after'][i], data['QoL_improvement'][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code generates the data. Now commented because it obviously overwrites the csv files each run\n",
    "# and we do not wish to do that each time. \n",
    "# TODO: At some point, need to make better data because this one will not work well. (See PROBLEMS below)\n",
    "\n",
    "# This is the folder where the data is stuffed. The folder doesn't have to exist, \n",
    "# if it does not exist, the folder will be created\n",
    "folder = 'data_initial'\n",
    "\n",
    "synthetic_data_dict = {} # Storing all generated data here\n",
    "# for index, row in df.iterrows():\n",
    "    # Generating data for each row in the df and adding that to the dict with the row index being the key\n",
    "    # synthetic_data_dict[index] = generate_data(row)\n",
    "    # filename = f\"data_{index}.csv\"\n",
    "    # write_to_csv(synthetic_data_dict[index], filename, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">PROBLEMS</span>\n",
    "* Negative values in the objective function data, that should not be allowed to happen since the values aren't realistic.\n",
    "* Improvement rates are bloody ridiculous, they are not realistic at all. I think it is because of the negative values in the data, they are messing with the improvement calculations. Need to weed out the negative values and perhaps introduce some sort of correlation between the before and after levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here importing the data from csv files into dataframes\n",
    "\n",
    "# the folder where the data is hanging out\n",
    "# this will import ALL the .csv files within that folder\n",
    "directory = \"./data_initial\"  \n",
    "\n",
    "dataframes_dict = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename) # path to the file\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Key is the filename without the .csv ending\n",
    "        dataframes_dict[filename[:-4]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pain_before</th>\n",
       "      <th>pain_after</th>\n",
       "      <th>pain_improvement</th>\n",
       "      <th>func_before</th>\n",
       "      <th>func_after</th>\n",
       "      <th>func_improvement</th>\n",
       "      <th>QoL_before</th>\n",
       "      <th>QoL_after</th>\n",
       "      <th>QoL_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.147821</td>\n",
       "      <td>31.770124</td>\n",
       "      <td>6.932760</td>\n",
       "      <td>8.520719</td>\n",
       "      <td>-22.905143</td>\n",
       "      <td>11.747159</td>\n",
       "      <td>18.905453</td>\n",
       "      <td>-60.936382</td>\n",
       "      <td>67.071871</td>\n",
       "      <td>69.083039</td>\n",
       "      <td>2.998526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.843777</td>\n",
       "      <td>21.802928</td>\n",
       "      <td>5.173638</td>\n",
       "      <td>12.572855</td>\n",
       "      <td>-143.017659</td>\n",
       "      <td>6.246227</td>\n",
       "      <td>30.754903</td>\n",
       "      <td>-392.375708</td>\n",
       "      <td>71.991398</td>\n",
       "      <td>85.024808</td>\n",
       "      <td>18.104122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.458339</td>\n",
       "      <td>24.669889</td>\n",
       "      <td>7.547620</td>\n",
       "      <td>8.450204</td>\n",
       "      <td>-11.958537</td>\n",
       "      <td>9.040084</td>\n",
       "      <td>34.294863</td>\n",
       "      <td>-279.364405</td>\n",
       "      <td>77.029963</td>\n",
       "      <td>56.682978</td>\n",
       "      <td>-26.414377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.827657</td>\n",
       "      <td>20.508080</td>\n",
       "      <td>8.210735</td>\n",
       "      <td>-2.539558</td>\n",
       "      <td>130.929722</td>\n",
       "      <td>23.622446</td>\n",
       "      <td>31.354798</td>\n",
       "      <td>-32.733068</td>\n",
       "      <td>49.017837</td>\n",
       "      <td>68.534876</td>\n",
       "      <td>39.816199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.370409</td>\n",
       "      <td>22.346341</td>\n",
       "      <td>7.745284</td>\n",
       "      <td>1.179480</td>\n",
       "      <td>84.771633</td>\n",
       "      <td>28.632475</td>\n",
       "      <td>2.003867</td>\n",
       "      <td>93.001418</td>\n",
       "      <td>66.795140</td>\n",
       "      <td>67.676838</td>\n",
       "      <td>1.320002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        bmi  pain_before  pain_after  pain_improvement  \\\n",
       "0  66.147821  31.770124     6.932760    8.520719        -22.905143   \n",
       "1  63.843777  21.802928     5.173638   12.572855       -143.017659   \n",
       "2  69.458339  24.669889     7.547620    8.450204        -11.958537   \n",
       "3  72.827657  20.508080     8.210735   -2.539558        130.929722   \n",
       "4  62.370409  22.346341     7.745284    1.179480         84.771633   \n",
       "\n",
       "   func_before  func_after  func_improvement  QoL_before  QoL_after  \\\n",
       "0    11.747159   18.905453        -60.936382   67.071871  69.083039   \n",
       "1     6.246227   30.754903       -392.375708   71.991398  85.024808   \n",
       "2     9.040084   34.294863       -279.364405   77.029963  56.682978   \n",
       "3    23.622446   31.354798        -32.733068   49.017837  68.534876   \n",
       "4    28.632475    2.003867         93.001418   66.795140  67.676838   \n",
       "\n",
       "   QoL_improvement  \n",
       "0         2.998526  \n",
       "1        18.104122  \n",
       "2       -26.414377  \n",
       "3        39.816199  \n",
       "4         1.320002  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dict['data_an_2008_control'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogates\n",
    "\n",
    "I'm not quite sure how we are supposed to fit the surrogates. I think it would be best to just fit it to the exercise groups, since that the performance of that is what we are interested in. I don't really know how we even could utilize the control groups here. \n",
    "\n",
    "So, I will only be fitting the surrogates to the exercise group datasets here. Also, I am assuming that the point is to see if age and bmi affect the results (meaning the improvement percentage)\n",
    "\n",
    "Also not sure if the performance metric R^2 was a good choice, it was just convenient \n",
    "\n",
    "*Should probably choose at least 2, maybe even 3 or 4 and do some analysis on those so we can find out which works the best.*\n",
    "- Chosen surrogates for further evaluation and testing:\n",
    "    - SVM \n",
    "    - \n",
    "    -\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data and scaling it\n",
    "\n",
    "* Fitting the surrogates only for the exercise groups. \n",
    "* Scaling the data since some of the methods (I think) are better with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the dataframes about the exercise groups\n",
    "\n",
    "# These are the keys for the exercise group dataframse\n",
    "ex_keys = [k for k in dataframes_dict.keys() if \"exercise\" in k]\n",
    "exercise_dataframes_dict = {}\n",
    "for key in ex_keys:\n",
    "    exercise_dataframes_dict[key] = dataframes_dict[key].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11 different therapies in the data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pain_before</th>\n",
       "      <th>pain_after</th>\n",
       "      <th>pain_improvement</th>\n",
       "      <th>func_before</th>\n",
       "      <th>func_after</th>\n",
       "      <th>func_improvement</th>\n",
       "      <th>QoL_before</th>\n",
       "      <th>QoL_after</th>\n",
       "      <th>QoL_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.095656</td>\n",
       "      <td>23.163583</td>\n",
       "      <td>7.950896</td>\n",
       "      <td>2.963848</td>\n",
       "      <td>62.723098</td>\n",
       "      <td>6.277190</td>\n",
       "      <td>11.304656</td>\n",
       "      <td>-80.091022</td>\n",
       "      <td>72.351706</td>\n",
       "      <td>77.230457</td>\n",
       "      <td>6.743103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.284960</td>\n",
       "      <td>28.579256</td>\n",
       "      <td>7.610465</td>\n",
       "      <td>-5.586427</td>\n",
       "      <td>173.404544</td>\n",
       "      <td>0.974135</td>\n",
       "      <td>11.278822</td>\n",
       "      <td>-1057.829350</td>\n",
       "      <td>56.919931</td>\n",
       "      <td>83.668522</td>\n",
       "      <td>46.993364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.170737</td>\n",
       "      <td>22.842774</td>\n",
       "      <td>10.570031</td>\n",
       "      <td>5.500836</td>\n",
       "      <td>47.958188</td>\n",
       "      <td>21.831200</td>\n",
       "      <td>0.997755</td>\n",
       "      <td>95.429682</td>\n",
       "      <td>84.001932</td>\n",
       "      <td>79.968487</td>\n",
       "      <td>-4.801610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.127090</td>\n",
       "      <td>27.460322</td>\n",
       "      <td>8.936780</td>\n",
       "      <td>8.036707</td>\n",
       "      <td>10.071564</td>\n",
       "      <td>19.192646</td>\n",
       "      <td>33.250728</td>\n",
       "      <td>-73.247228</td>\n",
       "      <td>55.577144</td>\n",
       "      <td>89.931924</td>\n",
       "      <td>61.814584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.207988</td>\n",
       "      <td>26.477881</td>\n",
       "      <td>8.732150</td>\n",
       "      <td>8.677388</td>\n",
       "      <td>0.627123</td>\n",
       "      <td>3.472480</td>\n",
       "      <td>-5.232589</td>\n",
       "      <td>250.687392</td>\n",
       "      <td>71.616582</td>\n",
       "      <td>71.130541</td>\n",
       "      <td>-0.678672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        bmi  pain_before  pain_after  pain_improvement  \\\n",
       "0  65.095656  23.163583     7.950896    2.963848         62.723098   \n",
       "1  72.284960  28.579256     7.610465   -5.586427        173.404544   \n",
       "2  49.170737  22.842774    10.570031    5.500836         47.958188   \n",
       "3  63.127090  27.460322     8.936780    8.036707         10.071564   \n",
       "4  68.207988  26.477881     8.732150    8.677388          0.627123   \n",
       "\n",
       "   func_before  func_after  func_improvement  QoL_before  QoL_after  \\\n",
       "0     6.277190   11.304656        -80.091022   72.351706  77.230457   \n",
       "1     0.974135   11.278822      -1057.829350   56.919931  83.668522   \n",
       "2    21.831200    0.997755         95.429682   84.001932  79.968487   \n",
       "3    19.192646   33.250728        -73.247228   55.577144  89.931924   \n",
       "4     3.472480   -5.232589        250.687392   71.616582  71.130541   \n",
       "\n",
       "   QoL_improvement  \n",
       "0         6.743103  \n",
       "1        46.993364  \n",
       "2        -4.801610  \n",
       "3        61.814584  \n",
       "4        -0.678672  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"We have\", len(exercise_dataframes_dict.keys()), \"different therapies in the data\")\n",
    "exercise_dataframes_dict['data_an_2008_exercise'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "# df is the (exercise group) dataframe being used\n",
    "# y is the \"target\" we are trying to \"predict\" (should be either pain_improvement, func_improvement or QoL_improvement)\n",
    "def fit_svm(df, y):\n",
    "    # This here is our data\n",
    "    X = df[['age', 'bmi']]\n",
    "    y = df[y]\n",
    "\n",
    "    # Splitting it to training and testing\n",
    "    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    svr = svm.SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return r2, svr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# First should scale all the data. I'm assuming that all the data is somewhat similar so just one scaler for all is enough, don't need to\n",
    "# create one for each dataframe. Also need to remember to unscale the data in the end and only one scaler makes it easier\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for key in exercise_dataframes_dict.keys():\n",
    "    arr = scaler.fit_transform(exercise_dataframes_dict[key])\n",
    "    exercise_dataframes_dict[key] = pd.DataFrame(arr, columns=exercise_dataframes_dict[key].columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}  # Storing the results and fitted surrogates here \n",
    "\n",
    "options = ['pain_improvement', 'func_improvement', 'QoL_improvement']\n",
    "\n",
    "for key in exercise_dataframes_dict.keys():\n",
    "    temp = {}\n",
    "    for option in options:\n",
    "        r2, svr = fit_svm(exercise_dataframes_dict[key],  option)\n",
    "        temp[option] = {'r2': r2, 'svr': svr}\n",
    "    results_dict[key] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the dictionary is a bit confusing but should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pain_improvement': {'r2': -0.32556857292984565, 'svr': SVR()},\n",
       " 'func_improvement': {'r2': 0.11110495382631791, 'svr': SVR()},\n",
       " 'QoL_improvement': {'r2': -1.2643809980601897, 'svr': SVR()}}"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict['data_an_2008_exercise']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem formulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preferences provided by the DM in the original paper\n",
    "Acceptable minimum and maximum ranges for the objectives\n",
    "\n",
    "| |Costs (€) | Pain change (%) | Function change (%) | Supervised sessions | Period (weeks) |\n",
    "| -------|------------|------------------|----------------------|----------------------|----------------|\n",
    "| Iteration 1 | 300 | +30% | +25% | 0 | 8 |\n",
    "| | 600 | +15% | +15% | 15 | 26 |\n",
    "| Iteration 2  | 200 | +25% | +40% | 0 | 12 |\n",
    "| | 500 | +15% | +15% | 30 | 26 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
